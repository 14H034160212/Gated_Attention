{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/twisha96/Gated_Attention/blob/master/IMDB_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D0T3nxESJstz",
        "outputId": "7e5ea017-cd41-46cc-e28f-f4e3dd7c7231",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "!pip3 install torchtext==0.4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n",
            "\r\u001b[K     |██████▏                         | 10kB 18.4MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 30kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (1.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (4.38.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (1.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (1.18.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4) (3.0.4)\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed torchtext-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a9sHZi8rIXBC",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pdb\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.distributions\n",
        "import torch.optim as optim\n",
        "from torch import nn \n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from torchtext.vocab import Vectors, GloVe\n",
        "\n",
        "# from models.LSTM import LSTMClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6CtSKjSRaQdd",
        "colab": {}
      },
      "source": [
        "# model.py\n",
        "\n",
        "class GANet(torch.nn.Module):\n",
        "    def __init__(self, batch_size, num_classes, mlp_out_size, vocab_size, embedding_length, weights, aux_hidden_size = 100, backbone_hidden_size = 100, tau = 1, biDirectional_aux = False, biDirectional_backbone = False):\n",
        "        super(GANet, self).__init__() \n",
        "        \"\"\"\n",
        "        Arguments\n",
        "        ---------\n",
        "        batch_size : Size of the batch which is same as the batch_size of the data returned by the TorchText BucketIterator\n",
        "        output_size : 6 = (For TREC dataset)\n",
        "        hidden_sie : Size of the hidden_state of the LSTM   (// Later BiLSTM)\n",
        "        vocab_size : Size of the vocabulary containing unique words\n",
        "        embedding_length : Embeddding dimension of GloVe word embeddings\n",
        "        weights : Pre-trained GloVe word_embeddings which we will use to create our word_embedding look-up table \n",
        "\n",
        "        --------\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.num_classes = num_classes\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_length = embedding_length\n",
        "        self.aux_hidden_size = aux_hidden_size\n",
        "        self.backbone_hidden_size = backbone_hidden_size \n",
        "        self.mlp_out_size = mlp_out_size\n",
        "        self.biDirectional_aux = biDirectional_aux\n",
        "        self.biDirectional_backbone = biDirectional_backbone\n",
        "        self.tau = tau\n",
        "\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_length)\n",
        "        self.word_embeddings.weights = nn.Parameter(weights, requires_grad=False)\n",
        "\n",
        "#         self.auxiliary = AuxiliaryNet(self.batch_size, self.aux_hidden_size, self.embedding_length, self.biDirectional_aux, tau = self.tau)\n",
        "        self.backbone = BackboneNet(self.batch_size, self.backbone_hidden_size, self.embedding_length, self.biDirectional_backbone)\n",
        "        \n",
        "        if(self.biDirectional_backbone):\n",
        "            self.mlp = MLP(self.backbone_hidden_size * 2, self.mlp_out_size)\n",
        "            self.FF = nn.Linear(self.backbone_hidden_size * 2,num_classes)\n",
        "        else:\n",
        "            self.mlp = MLP(self.backbone_hidden_size, self.mlp_out_size)\n",
        "            self.FF = nn.Linear(self.backbone_hidden_size,self.num_classes)\n",
        "        # self.softmax = nn.Softmax(dim = -1)\n",
        "\n",
        "    def forward(self,input_sequence, is_train = True):\n",
        "        input_ = self.word_embeddings(input_sequence)\n",
        "        out_lstm, final_hidden_state = self.backbone(input_)\n",
        "#         print(\"Backbone out size: \", final_hidden_state.shape)\n",
        "#         print(\"Last hidden out size: \", final_hidden_state[-1].shape)\n",
        "        ff_output = self.FF(final_hidden_state[-1])\n",
        "#         print(\"FF out size: \", ff_output.shape)\n",
        "        predictions = torch.softmax(ff_output, dim = -1)\n",
        "        return predictions\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YT9xWP_MAVmq",
        "colab": {}
      },
      "source": [
        "class BackboneNet(torch.nn.Module):\n",
        "    \"\"\"\n",
        "        Arguments\n",
        "        ---------\n",
        "        batch_size : Size of the batch which is same as the batch_size of the data returned by the TorchText BucketIterator\n",
        "        backbone_hidden_size : Size of the hidden_state of the LSTM   (* Later BiLSTM, check dims for BiLSTM *)\n",
        "        embedding_length : Embeddding dimension of GloVe word embeddings\n",
        "        --------\n",
        "    \"\"\"\n",
        "    def __init__(self, batch_size, backbone_hidden_size, embedding_length, biDirectional = False, num_layers = 2):\n",
        "\n",
        "        super(BackboneNet, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.hidden_size = backbone_hidden_size\n",
        "        self.embedding_length = embedding_length\n",
        "        self.biDirectional\t= biDirectional\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.backbone_lstm = nn.LSTM(self.embedding_length, self.hidden_size, bidirectional = self.biDirectional, batch_first = True, num_layers = self.num_layers)   # Dropout  \n",
        "\n",
        "    def forward(self, input_sequence, batch_size=None):\n",
        "        out_lstm, (final_hidden_state, final_cell_state) = self.backbone_lstm(input_sequence)   # ouput dim: ( batch_size x seq_len x hidden_size )\n",
        "        return out_lstm, final_hidden_state\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x_eU0HR-j8lW",
        "colab": {}
      },
      "source": [
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.ff_1 = nn.Linear(self.input_dim, self.output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.ff_2 = nn.Linear(self.output_dim,1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self,x):\n",
        "        out_1 = self.ff_1(x)\n",
        "        out_relu = self.relu(out_1)\n",
        "        out_2 = self.ff_2(out_relu)\n",
        "        out_sigmoid = self.sigmoid(out_2)\n",
        "\n",
        "        return out_sigmoid "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Swz_WT2mS3zq",
        "colab": {}
      },
      "source": [
        "def clip_gradient(model, clip_value):\n",
        "    params = list(filter(lambda p: p.grad is not None, model.parameters()))\n",
        "    for p in params:\n",
        "        p.grad.data.clamp_(-clip_value, clip_value)\n",
        "    \n",
        "def train_model(model, optim, train_iter, epoch, batch_size):\n",
        "    total_epoch_loss = 0\n",
        "    total_epoch_acc = 0\n",
        "    # model.cuda()\n",
        "#     optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "    steps = 0\n",
        "    model.train()\n",
        "    for idx, batch in enumerate(train_iter):\n",
        "        text = batch.text[0]\n",
        "        target = batch.label\n",
        "        target = torch.autograd.Variable(target).long()\n",
        "        if torch.cuda.is_available():\n",
        "            text = text.cuda()\n",
        "            target = target.cuda()\n",
        "        if (text.size()[0] is not batch_size):# One of the batch returned by BucketIterator has length different than 32.\n",
        "            continue\n",
        "        optim.zero_grad()\n",
        "        prediction = model(text, is_train = True)\n",
        "#         print(\"prediction = \", prediction.shape)\n",
        "#         print(\"target = \", target.shape)\n",
        "#         print(\"prediction = \", prediction)\n",
        "#         print(\"target = \", target)\n",
        "\n",
        "\n",
        "        # Defualt - Cross entropy loss funtion\n",
        "        loss = loss_fn(prediction, target)\n",
        "        \n",
        "        # print(\"loss = \", loss)\n",
        "        \n",
        "        num_corrects = (torch.max(prediction, 1)[1].view(target.size()).data == target.data).float().sum()\n",
        "        acc = 100.0 * num_corrects/len(batch)\n",
        "        loss.backward()\n",
        "        clip_gradient(model, 1e-1)\n",
        "        optim.step()\n",
        "        steps += 1\n",
        "        \n",
        "        total_epoch_loss += loss.item()\n",
        "        total_epoch_acc += acc.item()\n",
        "\n",
        "        \n",
        "    return total_epoch_loss/len(train_iter), total_epoch_acc/len(train_iter)\n",
        "\n",
        "def eval_model(model, val_iter):\n",
        "    total_epoch_loss = 0\n",
        "    total_epoch_acc = 0\n",
        "    total_attention =  0\n",
        "    total_samples = 0 \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(val_iter):\n",
        "            text = batch.text[0]\n",
        "            if (text.size()[0] is not 32):\n",
        "                continue\n",
        "            target = batch.label\n",
        "            target = torch.autograd.Variable(target).long()\n",
        "            if torch.cuda.is_available():\n",
        "                text = text.cuda()\n",
        "                target = target.cuda()\n",
        "            prediction = model(text, is_train = False)\n",
        "            # Sanity check\n",
        "            # print(\"Test Prediction: \", prediction)\n",
        "\n",
        "            # Defualt - Cross entropy loss funtion\n",
        "            loss =  loss_fn(prediction, target)\n",
        "            \n",
        "            if math.isnan(loss.item()):\n",
        "                print(prediction, target)\n",
        "            \n",
        "            num_corrects = (torch.max(prediction, 1)[1].view(target.size()).data == target.data).sum()\n",
        "            acc = 100.0 * num_corrects/len(batch)\n",
        "            total_epoch_loss += loss.item()\n",
        "            total_epoch_acc += acc.item()\n",
        "            \n",
        "    return total_epoch_loss/len(val_iter), total_epoch_acc/len(val_iter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vAjlrmkGSEQQ",
        "colab": {}
      },
      "source": [
        "# data.py\n",
        "def load_IMDB_data(batch_size= 32, embedding_length = 100):\n",
        "    # set up fields\n",
        "    tokenize = lambda x: x.split()\n",
        "    TEXT = data.Field(sequential=True, tokenize=tokenize, lower=True, include_lengths=True, batch_first=True, fix_length= 100)\n",
        "    # LABEL = data.LabelField()\n",
        "    LABEL = data.LabelField(dtype=torch.float)\n",
        "\n",
        "    # make splits for data\n",
        "    train, test = datasets.IMDB.splits(TEXT, LABEL)\n",
        "    train, valid = train.split() \n",
        "    \n",
        "    # build the vocabulary\n",
        "    TEXT.build_vocab(train, vectors=GloVe(name='6B', dim=embedding_length))\n",
        "    LABEL.build_vocab(train)\n",
        "    print(LABEL.vocab.__dict__)\n",
        "\n",
        "    # make iterator for splits\n",
        "    train_iter, valid_iter, test_iter = data.BucketIterator.splits(\n",
        "      (train, valid, test), batch_size= batch_size, device=0)\n",
        "\n",
        "    word_embeddings = TEXT.vocab.vectors\n",
        "    vocab_size = len(TEXT.vocab)\n",
        "\n",
        "    return TEXT, vocab_size, word_embeddings, train_iter, valid_iter, test_iter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xHuvlEncW_tw",
        "outputId": "b58b768a-b798-4805-99c3-ca0451c6a54c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "# main.py\n",
        "TEXT, vocab_size, word_embeddings, train_iter, valid_iter, test_iter = load_IMDB_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "aclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]\u001b[A\n",
            "aclImdb_v1.tar.gz:   0%|          | 164k/84.1M [00:00<00:53, 1.56MB/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "aclImdb_v1.tar.gz:   1%|          | 590k/84.1M [00:00<00:44, 1.89MB/s]\u001b[A\n",
            "aclImdb_v1.tar.gz:   2%|▏         | 1.52M/84.1M [00:00<00:33, 2.46MB/s]\u001b[A\n",
            "aclImdb_v1.tar.gz:   4%|▍         | 3.24M/84.1M [00:00<00:24, 3.31MB/s]\u001b[A\n",
            "aclImdb_v1.tar.gz:   7%|▋         | 6.29M/84.1M [00:00<00:17, 4.52MB/s]\u001b[A\n",
            "aclImdb_v1.tar.gz:  13%|█▎        | 10.6M/84.1M [00:00<00:11, 6.16MB/s]\u001b[A\n",
            "aclImdb_v1.tar.gz:  19%|█▊        | 15.6M/84.1M [00:00<00:08, 8.36MB/s]\u001b[A\n",
            "aclImdb_v1.tar.gz:  26%|██▌       | 21.5M/84.1M [00:00<00:05, 11.2MB/s]\u001b[A\n",
            "aclImdb_v1.tar.gz:  34%|███▍      | 28.5M/84.1M [00:00<00:03, 15.0MB/s]\u001b[A\n",
            "aclImdb_v1.tar.gz:  44%|████▍     | 37.0M/84.1M [00:01<00:02, 19.9MB/s]\u001b[A\n",
            "aclImdb_v1.tar.gz:  56%|█████▌    | 47.0M/84.1M [00:01<00:01, 26.2MB/s]\u001b[A\n",
            "aclImdb_v1.tar.gz:  69%|██████▉   | 58.0M/84.1M [00:01<00:00, 34.0MB/s]\u001b[A\n",
            "aclImdb_v1.tar.gz:  82%|████████▏ | 69.3M/84.1M [00:01<00:00, 43.0MB/s]\u001b[A\n",
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:01<00:00, 57.0MB/s]\n",
            "WARNING:torchtext.data.iterator:The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
            "WARNING:torchtext.data.iterator:The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
            "WARNING:torchtext.data.iterator:The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'freqs': Counter({'neg': 8809, 'pos': 8691}), 'itos': ['neg', 'pos'], 'unk_index': None, 'stoi': defaultdict(None, {'neg': 0, 'pos': 1}), 'vectors': None}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PImJSOJmzQgT",
        "colab": {}
      },
      "source": [
        "# Over-writing the loss function to simple cross entropy loss\n",
        "loss_fn = F.cross_entropy\n",
        "\n",
        "learning_rate = 2e-5\n",
        "batch_size = 32\n",
        "output_size = 2\n",
        "hidden_size = 256\n",
        "embedding_length = 100\n",
        "num_classes = 2\n",
        "mlp_out_size = 32\n",
        "weights = word_embeddings\n",
        "aux_hidden_size = 100\n",
        "batch_hidden_size = 100\n",
        "tau = 1\n",
        "\n",
        "model = GANet(batch_size, num_classes, mlp_out_size, vocab_size, embedding_length, weights, biDirectional_backbone=False)\n",
        "optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EcU6SSW8bDln",
        "outputId": "467f7a71-074a-48e7-a69a-a23f39b24ed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_bad_epochs = 0\n",
        "epoch = 0\n",
        "least_loss = float('inf')\n",
        "training_stats = pd.DataFrame(columns=['Epoch', 'Train_Loss', 'Train_Acc', 'Val_Loss', 'Val_Acc'])\n",
        "\n",
        "while(True):\n",
        "    train_loss, train_acc = train_model(model, optim, train_iter, epoch, batch_size)\n",
        "    val_loss, val_acc = eval_model(model, valid_iter) \n",
        "    print(f'Epoch: {epoch+1:02}')\n",
        "    if val_loss < least_loss:\n",
        "        least_loss = val_loss\n",
        "        num_bad_epochs = 0\n",
        "        print(\"*** Least validation loss\")\n",
        "        torch.save(model.state_dict(), \"IMDB_LSTM_100\")\n",
        "    else:\n",
        "        num_bad_epochs += 1\n",
        "#     print(f'Epoch: {epoch+1:2}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%')\n",
        "    print(f'Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%') \n",
        "    print(f'Val Loss: {val_loss:3f}, Val Acc: {val_acc:.2f}%')\n",
        "    print(\"-------------\")\n",
        "    \n",
        "    training_stats = training_stats.append(\n",
        "        pd.Series([epoch+1, train_loss, train_acc, val_loss, val_acc], index=training_stats.columns), \n",
        "        ignore_index=True)\n",
        "#     if num_bad_epochs >= 10:\n",
        "#         break\n",
        "        \n",
        "    epoch += 1\n",
        "    if epoch == 100:\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01\n",
            "*** Least validation loss\n",
            "Train Loss: 0.691, Train Acc: 51.87%\n",
            "Val Loss: 0.689750, Val Acc: 50.32%\n",
            "-------------\n",
            "Epoch: 02\n",
            "Train Loss: 0.691, Train Acc: 51.17%\n",
            "Val Loss: 0.689777, Val Acc: 50.36%\n",
            "-------------\n",
            "Epoch: 03\n",
            "Train Loss: 0.682, Train Acc: 54.90%\n",
            "Val Loss: 0.689855, Val Acc: 50.28%\n",
            "-------------\n",
            "Epoch: 04\n",
            "*** Least validation loss\n",
            "Train Loss: 0.683, Train Acc: 53.90%\n",
            "Val Loss: 0.626653, Val Acc: 66.49%\n",
            "-------------\n",
            "Epoch: 05\n",
            "*** Least validation loss\n",
            "Train Loss: 0.580, Train Acc: 71.85%\n",
            "Val Loss: 0.569259, Val Acc: 71.78%\n",
            "-------------\n",
            "Epoch: 06\n",
            "*** Least validation loss\n",
            "Train Loss: 0.478, Train Acc: 82.66%\n",
            "Val Loss: 0.545193, Val Acc: 74.97%\n",
            "-------------\n",
            "Epoch: 07\n",
            "*** Least validation loss\n",
            "Train Loss: 0.422, Train Acc: 88.45%\n",
            "Val Loss: 0.544505, Val Acc: 75.01%\n",
            "-------------\n",
            "Epoch: 08\n",
            "Train Loss: 0.390, Train Acc: 91.98%\n",
            "Val Loss: 0.546766, Val Acc: 75.11%\n",
            "-------------\n",
            "Epoch: 09\n",
            "Train Loss: 0.378, Train Acc: 93.24%\n",
            "Val Loss: 0.548351, Val Acc: 75.20%\n",
            "-------------\n",
            "Epoch: 10\n",
            "*** Least validation loss\n",
            "Train Loss: 0.371, Train Acc: 93.94%\n",
            "Val Loss: 0.542390, Val Acc: 76.09%\n",
            "-------------\n",
            "Epoch: 11\n",
            "*** Least validation loss\n",
            "Train Loss: 0.364, Train Acc: 94.70%\n",
            "Val Loss: 0.534107, Val Acc: 76.93%\n",
            "-------------\n",
            "Epoch: 12\n",
            "Train Loss: 0.361, Train Acc: 94.98%\n",
            "Val Loss: 0.544699, Val Acc: 75.86%\n",
            "-------------\n",
            "Epoch: 13\n",
            "Train Loss: 0.356, Train Acc: 95.45%\n",
            "Val Loss: 0.536564, Val Acc: 76.77%\n",
            "-------------\n",
            "Epoch: 14\n",
            "Train Loss: 0.356, Train Acc: 95.41%\n",
            "Val Loss: 0.541423, Val Acc: 76.20%\n",
            "-------------\n",
            "Epoch: 15\n",
            "Train Loss: 0.353, Train Acc: 95.76%\n",
            "Val Loss: 0.538788, Val Acc: 76.40%\n",
            "-------------\n",
            "Epoch: 16\n",
            "*** Least validation loss\n",
            "Train Loss: 0.350, Train Acc: 96.05%\n",
            "Val Loss: 0.530776, Val Acc: 77.43%\n",
            "-------------\n",
            "Epoch: 17\n",
            "Train Loss: 0.349, Train Acc: 96.16%\n",
            "Val Loss: 0.535372, Val Acc: 76.93%\n",
            "-------------\n",
            "Epoch: 18\n",
            "Train Loss: 0.347, Train Acc: 96.34%\n",
            "Val Loss: 0.554070, Val Acc: 75.04%\n",
            "-------------\n",
            "Epoch: 19\n",
            "Train Loss: 0.346, Train Acc: 96.48%\n",
            "Val Loss: 0.539241, Val Acc: 76.46%\n",
            "-------------\n",
            "Epoch: 20\n",
            "Train Loss: 0.348, Train Acc: 96.32%\n",
            "Val Loss: 0.540084, Val Acc: 76.46%\n",
            "-------------\n",
            "Epoch: 21\n",
            "Train Loss: 0.344, Train Acc: 96.64%\n",
            "Val Loss: 0.537710, Val Acc: 76.76%\n",
            "-------------\n",
            "Epoch: 22\n",
            "Train Loss: 0.344, Train Acc: 96.69%\n",
            "Val Loss: 0.533364, Val Acc: 77.23%\n",
            "-------------\n",
            "Epoch: 23\n",
            "Train Loss: 0.345, Train Acc: 96.61%\n",
            "Val Loss: 0.534570, Val Acc: 77.05%\n",
            "-------------\n",
            "Epoch: 24\n",
            "Train Loss: 0.341, Train Acc: 97.01%\n",
            "Val Loss: 0.533368, Val Acc: 77.26%\n",
            "-------------\n",
            "Epoch: 25\n",
            "Train Loss: 0.341, Train Acc: 97.02%\n",
            "Val Loss: 0.537706, Val Acc: 76.78%\n",
            "-------------\n",
            "Epoch: 26\n",
            "Train Loss: 0.341, Train Acc: 96.97%\n",
            "Val Loss: 0.536642, Val Acc: 76.77%\n",
            "-------------\n",
            "Epoch: 27\n",
            "Train Loss: 0.339, Train Acc: 97.15%\n",
            "Val Loss: 0.538402, Val Acc: 76.58%\n",
            "-------------\n",
            "Epoch: 28\n",
            "*** Least validation loss\n",
            "Train Loss: 0.339, Train Acc: 97.20%\n",
            "Val Loss: 0.530528, Val Acc: 77.27%\n",
            "-------------\n",
            "Epoch: 29\n",
            "Train Loss: 0.338, Train Acc: 97.34%\n",
            "Val Loss: 0.535213, Val Acc: 76.91%\n",
            "-------------\n",
            "Epoch: 30\n",
            "Train Loss: 0.337, Train Acc: 97.34%\n",
            "Val Loss: 0.540550, Val Acc: 76.34%\n",
            "-------------\n",
            "Epoch: 31\n",
            "Train Loss: 0.338, Train Acc: 97.33%\n",
            "Val Loss: 0.538688, Val Acc: 76.69%\n",
            "-------------\n",
            "Epoch: 32\n",
            "Train Loss: 0.337, Train Acc: 97.38%\n",
            "Val Loss: 0.535312, Val Acc: 77.06%\n",
            "-------------\n",
            "Epoch: 33\n",
            "Train Loss: 0.338, Train Acc: 97.33%\n",
            "Val Loss: 0.538556, Val Acc: 76.74%\n",
            "-------------\n",
            "Epoch: 34\n",
            "Train Loss: 0.336, Train Acc: 97.45%\n",
            "Val Loss: 0.540140, Val Acc: 76.46%\n",
            "-------------\n",
            "Epoch: 35\n",
            "Train Loss: 0.336, Train Acc: 97.54%\n",
            "Val Loss: 0.532960, Val Acc: 77.31%\n",
            "-------------\n",
            "Epoch: 36\n",
            "Train Loss: 0.335, Train Acc: 97.63%\n",
            "Val Loss: 0.539028, Val Acc: 76.69%\n",
            "-------------\n",
            "Epoch: 37\n",
            "Train Loss: 0.334, Train Acc: 97.68%\n",
            "Val Loss: 0.540124, Val Acc: 76.53%\n",
            "-------------\n",
            "Epoch: 38\n",
            "Train Loss: 0.334, Train Acc: 97.73%\n",
            "Val Loss: 0.538216, Val Acc: 76.78%\n",
            "-------------\n",
            "Epoch: 39\n",
            "Train Loss: 0.334, Train Acc: 97.69%\n",
            "Val Loss: 0.541135, Val Acc: 76.49%\n",
            "-------------\n",
            "Epoch: 40\n",
            "Train Loss: 0.334, Train Acc: 97.65%\n",
            "Val Loss: 0.536710, Val Acc: 76.73%\n",
            "-------------\n",
            "Epoch: 41\n",
            "Train Loss: 0.334, Train Acc: 97.65%\n",
            "Val Loss: 0.535389, Val Acc: 76.97%\n",
            "-------------\n",
            "Epoch: 42\n",
            "Train Loss: 0.334, Train Acc: 97.68%\n",
            "Val Loss: 0.531206, Val Acc: 77.38%\n",
            "-------------\n",
            "Epoch: 43\n",
            "Train Loss: 0.332, Train Acc: 97.84%\n",
            "Val Loss: 0.534619, Val Acc: 77.01%\n",
            "-------------\n",
            "Epoch: 44\n",
            "Train Loss: 0.334, Train Acc: 97.73%\n",
            "Val Loss: 0.543423, Val Acc: 76.14%\n",
            "-------------\n",
            "Epoch: 45\n",
            "Train Loss: 0.333, Train Acc: 97.83%\n",
            "Val Loss: 0.553584, Val Acc: 75.19%\n",
            "-------------\n",
            "Epoch: 46\n",
            "Train Loss: 0.333, Train Acc: 97.76%\n",
            "Val Loss: 0.540902, Val Acc: 76.45%\n",
            "-------------\n",
            "Epoch: 47\n",
            "Train Loss: 0.332, Train Acc: 97.93%\n",
            "Val Loss: 0.539911, Val Acc: 76.58%\n",
            "-------------\n",
            "Epoch: 48\n",
            "Train Loss: 0.332, Train Acc: 97.89%\n",
            "Val Loss: 0.537126, Val Acc: 76.89%\n",
            "-------------\n",
            "Epoch: 49\n",
            "Train Loss: 0.331, Train Acc: 97.98%\n",
            "Val Loss: 0.534876, Val Acc: 77.07%\n",
            "-------------\n",
            "Epoch: 50\n",
            "Train Loss: 0.331, Train Acc: 97.96%\n",
            "Val Loss: 0.535229, Val Acc: 77.07%\n",
            "-------------\n",
            "Epoch: 51\n",
            "Train Loss: 0.331, Train Acc: 97.99%\n",
            "Val Loss: 0.538892, Val Acc: 76.74%\n",
            "-------------\n",
            "Epoch: 52\n",
            "Train Loss: 0.331, Train Acc: 97.99%\n",
            "Val Loss: 0.539481, Val Acc: 76.53%\n",
            "-------------\n",
            "Epoch: 53\n",
            "Train Loss: 0.331, Train Acc: 98.03%\n",
            "Val Loss: 0.535308, Val Acc: 76.97%\n",
            "-------------\n",
            "Epoch: 54\n",
            "Train Loss: 0.331, Train Acc: 98.00%\n",
            "Val Loss: 0.539291, Val Acc: 76.62%\n",
            "-------------\n",
            "Epoch: 55\n",
            "Train Loss: 0.331, Train Acc: 97.97%\n",
            "Val Loss: 0.536741, Val Acc: 76.98%\n",
            "-------------\n",
            "Epoch: 56\n",
            "Train Loss: 0.330, Train Acc: 98.09%\n",
            "Val Loss: 0.538991, Val Acc: 76.64%\n",
            "-------------\n",
            "Epoch: 57\n",
            "Train Loss: 0.329, Train Acc: 98.14%\n",
            "Val Loss: 0.532696, Val Acc: 77.29%\n",
            "-------------\n",
            "Epoch: 58\n",
            "Train Loss: 0.330, Train Acc: 98.06%\n",
            "Val Loss: 0.540343, Val Acc: 76.45%\n",
            "-------------\n",
            "Epoch: 59\n",
            "Train Loss: 0.330, Train Acc: 98.09%\n",
            "Val Loss: 0.535526, Val Acc: 76.98%\n",
            "-------------\n",
            "Epoch: 60\n",
            "Train Loss: 0.331, Train Acc: 98.02%\n",
            "Val Loss: 0.536852, Val Acc: 76.78%\n",
            "-------------\n",
            "Epoch: 61\n",
            "Train Loss: 0.330, Train Acc: 98.03%\n",
            "Val Loss: 0.532591, Val Acc: 77.38%\n",
            "-------------\n",
            "Epoch: 62\n",
            "Train Loss: 0.330, Train Acc: 98.11%\n",
            "Val Loss: 0.540008, Val Acc: 76.60%\n",
            "-------------\n",
            "Epoch: 63\n",
            "Train Loss: 0.329, Train Acc: 98.18%\n",
            "Val Loss: 0.557813, Val Acc: 74.85%\n",
            "-------------\n",
            "Epoch: 64\n",
            "*** Least validation loss\n",
            "Train Loss: 0.329, Train Acc: 98.22%\n",
            "Val Loss: 0.529804, Val Acc: 77.51%\n",
            "-------------\n",
            "Epoch: 65\n",
            "Train Loss: 0.329, Train Acc: 98.23%\n",
            "Val Loss: 0.530634, Val Acc: 77.61%\n",
            "-------------\n",
            "Epoch: 66\n",
            "Train Loss: 0.329, Train Acc: 98.19%\n",
            "Val Loss: 0.547295, Val Acc: 75.78%\n",
            "-------------\n",
            "Epoch: 67\n",
            "Train Loss: 0.329, Train Acc: 98.18%\n",
            "Val Loss: 0.535393, Val Acc: 77.10%\n",
            "-------------\n",
            "Epoch: 68\n",
            "Train Loss: 0.329, Train Acc: 98.13%\n",
            "Val Loss: 0.533962, Val Acc: 77.15%\n",
            "-------------\n",
            "Epoch: 69\n",
            "Train Loss: 0.328, Train Acc: 98.24%\n",
            "Val Loss: 0.530939, Val Acc: 77.47%\n",
            "-------------\n",
            "Epoch: 70\n",
            "Train Loss: 0.329, Train Acc: 98.23%\n",
            "Val Loss: 0.560663, Val Acc: 74.38%\n",
            "-------------\n",
            "Epoch: 71\n",
            "Train Loss: 0.328, Train Acc: 98.25%\n",
            "Val Loss: 0.534578, Val Acc: 77.18%\n",
            "-------------\n",
            "Epoch: 72\n",
            "Train Loss: 0.328, Train Acc: 98.27%\n",
            "Val Loss: 0.534638, Val Acc: 77.09%\n",
            "-------------\n",
            "Epoch: 73\n",
            "Train Loss: 0.329, Train Acc: 98.15%\n",
            "Val Loss: 0.537640, Val Acc: 76.82%\n",
            "-------------\n",
            "Epoch: 74\n",
            "Train Loss: 0.329, Train Acc: 98.19%\n",
            "Val Loss: 0.537761, Val Acc: 76.72%\n",
            "-------------\n",
            "Epoch: 75\n",
            "Train Loss: 0.328, Train Acc: 98.29%\n",
            "Val Loss: 0.538758, Val Acc: 76.62%\n",
            "-------------\n",
            "Epoch: 76\n",
            "Train Loss: 0.328, Train Acc: 98.23%\n",
            "Val Loss: 0.533379, Val Acc: 77.25%\n",
            "-------------\n",
            "Epoch: 77\n",
            "Train Loss: 0.328, Train Acc: 98.30%\n",
            "Val Loss: 0.535968, Val Acc: 76.90%\n",
            "-------------\n",
            "Epoch: 78\n",
            "Train Loss: 0.328, Train Acc: 98.33%\n",
            "Val Loss: 0.536115, Val Acc: 76.86%\n",
            "-------------\n",
            "Epoch: 79\n",
            "Train Loss: 0.327, Train Acc: 98.34%\n",
            "Val Loss: 0.536338, Val Acc: 76.93%\n",
            "-------------\n",
            "Epoch: 80\n",
            "Train Loss: 0.327, Train Acc: 98.34%\n",
            "Val Loss: 0.539616, Val Acc: 76.54%\n",
            "-------------\n",
            "Epoch: 81\n",
            "Train Loss: 0.328, Train Acc: 98.30%\n",
            "Val Loss: 0.535670, Val Acc: 77.09%\n",
            "-------------\n",
            "Epoch: 82\n",
            "Train Loss: 0.330, Train Acc: 98.13%\n",
            "Val Loss: 0.536154, Val Acc: 77.03%\n",
            "-------------\n",
            "Epoch: 83\n",
            "Train Loss: 0.328, Train Acc: 98.30%\n",
            "Val Loss: 0.537807, Val Acc: 76.69%\n",
            "-------------\n",
            "Epoch: 84\n",
            "Train Loss: 0.327, Train Acc: 98.35%\n",
            "Val Loss: 0.534904, Val Acc: 77.11%\n",
            "-------------\n",
            "Epoch: 85\n",
            "Train Loss: 0.327, Train Acc: 98.37%\n",
            "Val Loss: 0.535061, Val Acc: 77.11%\n",
            "-------------\n",
            "Epoch: 86\n",
            "Train Loss: 0.327, Train Acc: 98.38%\n",
            "Val Loss: 0.535163, Val Acc: 77.09%\n",
            "-------------\n",
            "Epoch: 87\n",
            "Train Loss: 0.327, Train Acc: 98.37%\n",
            "Val Loss: 0.535264, Val Acc: 77.11%\n",
            "-------------\n",
            "Epoch: 88\n",
            "Train Loss: 0.327, Train Acc: 98.37%\n",
            "Val Loss: 0.535372, Val Acc: 77.10%\n",
            "-------------\n",
            "Epoch: 89\n",
            "Train Loss: 0.327, Train Acc: 98.37%\n",
            "Val Loss: 0.534344, Val Acc: 77.15%\n",
            "-------------\n",
            "Epoch: 90\n",
            "Train Loss: 0.327, Train Acc: 98.38%\n",
            "Val Loss: 0.536306, Val Acc: 76.90%\n",
            "-------------\n",
            "Epoch: 91\n",
            "Train Loss: 0.329, Train Acc: 98.21%\n",
            "Val Loss: 0.535659, Val Acc: 76.91%\n",
            "-------------\n",
            "Epoch: 92\n",
            "Train Loss: 0.328, Train Acc: 98.33%\n",
            "Val Loss: 0.541186, Val Acc: 76.46%\n",
            "-------------\n",
            "Epoch: 93\n",
            "Train Loss: 0.328, Train Acc: 98.28%\n",
            "Val Loss: 0.541464, Val Acc: 76.44%\n",
            "-------------\n",
            "Epoch: 94\n",
            "Train Loss: 0.327, Train Acc: 98.37%\n",
            "Val Loss: 0.540159, Val Acc: 76.57%\n",
            "-------------\n",
            "Epoch: 95\n",
            "Train Loss: 0.327, Train Acc: 98.37%\n",
            "Val Loss: 0.537187, Val Acc: 76.88%\n",
            "-------------\n",
            "Epoch: 96\n",
            "Train Loss: 0.327, Train Acc: 98.39%\n",
            "Val Loss: 0.539139, Val Acc: 76.52%\n",
            "-------------\n",
            "Epoch: 97\n",
            "Train Loss: 0.327, Train Acc: 98.40%\n",
            "Val Loss: 0.539293, Val Acc: 76.50%\n",
            "-------------\n",
            "Epoch: 98\n",
            "Train Loss: 0.327, Train Acc: 98.43%\n",
            "Val Loss: 0.545046, Val Acc: 76.05%\n",
            "-------------\n",
            "Epoch: 99\n",
            "Train Loss: 0.327, Train Acc: 98.42%\n",
            "Val Loss: 0.539252, Val Acc: 76.61%\n",
            "-------------\n",
            "Epoch: 100\n",
            "Train Loss: 0.326, Train Acc: 98.44%\n",
            "Val Loss: 0.537367, Val Acc: 76.88%\n",
            "-------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "CLa2VNHk3Dy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_stats.to_csv(\"IMDB_LSTM_100.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7DFB8w73DzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Print model's state_dict\n",
        "# print(\"Model's state_dict:\")\n",
        "# for param_tensor in model.state_dict():\n",
        "#     print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "\n",
        "# # Print optimizer's state_dict\n",
        "# print(\"Optimizer's state_dict:\")\n",
        "# for var_name in optim.state_dict():\n",
        "#     print(var_name, \"\\t\", optim.state_dict()[var_name])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XISLc_M3DzG",
        "colab_type": "code",
        "outputId": "b138219c-bce0-4dd1-d12e-6a97854f2566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "loaded_model = GANet(batch_size, num_classes, mlp_out_size, vocab_size, embedding_length, weights,biDirectional_backbone=False)\n",
        "loaded_model.load_state_dict(torch.load('IMDB_LSTM_100'))\n",
        "loaded_model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GANet(\n",
              "  (word_embeddings): Embedding(202329, 100)\n",
              "  (backbone): BackboneNet(\n",
              "    (backbone_lstm): LSTM(100, 100, num_layers=2, batch_first=True)\n",
              "  )\n",
              "  (mlp): MLP(\n",
              "    (ff_1): Linear(in_features=100, out_features=32, bias=True)\n",
              "    (relu): ReLU()\n",
              "    (ff_2): Linear(in_features=32, out_features=1, bias=True)\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              "  (FF): Linear(in_features=100, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vwMLkn7s7cnC",
        "outputId": "906314d4-6f79-48f8-c54c-75a7c2c5998d",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss, test_acc = eval_model(loaded_model, test_iter)\n",
        "print(f'Test Loss: {test_loss:.3f}, Test Acc: {test_acc:.2f}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.555, Test Acc: 75.49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kj2OOxjKaAIm",
        "outputId": "fdec2e0c-be86-4514-b714-6b0409642238",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "def test_sentence(test_sen):\n",
        "    test_sen_list = TEXT.preprocess(test_sen)\n",
        "    print(test_sen_list)\n",
        "    test_sen = [[TEXT.vocab.stoi[x] for x in test_sen_list]]\n",
        "    # print(test_sen)\n",
        "\n",
        "    test_sen = np.asarray(test_sen)\n",
        "    test_sen = torch.LongTensor(test_sen)\n",
        "    test_tensor = Variable(test_sen, volatile=True)\n",
        "\n",
        "    # print(test_tensor)\n",
        "    loaded_model.eval()\n",
        "    prediction = loaded_model(test_tensor, is_train = False)\n",
        "    print(\"prediction =\", prediction)\n",
        "\n",
        "    out_class = torch.argmax(prediction)\n",
        "    return out_class\n",
        "\n",
        "\n",
        "''' Let us now predict the sentiment on a single sentence just for the testing purpose. '''\n",
        "test_sen1 = \"This is one of the best creation of Nolan. I can say, it's his magnum opus. Loved the soundtrack and especially those creative dialogues.\"\n",
        "test_sen2 = \"Ohh, such a ridiculous movie. Not gonna recommend it to anyone. Complete waste of time and money.\"\n",
        "\n",
        "print('------------')\n",
        "x = test_sentence(test_sen1)\n",
        "print(x)\n",
        "print('------------')\n",
        "x = test_sentence(test_sen2)\n",
        "print(x)\n",
        "print('------------')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------\n",
            "['this', 'is', 'one', 'of', 'the', 'best', 'creation', 'of', 'nolan.', 'i', 'can', 'say,', \"it's\", 'his', 'magnum', 'opus.', 'loved', 'the', 'soundtrack', 'and', 'especially', 'those', 'creative', 'dialogues.']\n",
            "prediction = tensor([[2.4315e-08, 1.0000e+00]], grad_fn=<SoftmaxBackward>)\n",
            "tensor(1)\n",
            "------------\n",
            "['ohh,', 'such', 'a', 'ridiculous', 'movie.', 'not', 'gonna', 'recommend', 'it', 'to', 'anyone.', 'complete', 'waste', 'of', 'time', 'and', 'money.']\n",
            "prediction = tensor([[1.0000e+00, 7.9843e-09]], grad_fn=<SoftmaxBackward>)\n",
            "tensor(0)\n",
            "------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DJf5OMBaO8Wl",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yncx9F0C3DzS",
        "colab_type": "code",
        "outputId": "c10db1b6-5315-4103-fc36-22db18d00805",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "training_stats"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Epoch</th>\n",
              "      <th>Train_Loss</th>\n",
              "      <th>Train_Acc</th>\n",
              "      <th>Val_Loss</th>\n",
              "      <th>Val_Acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.690962</td>\n",
              "      <td>51.868144</td>\n",
              "      <td>0.689750</td>\n",
              "      <td>50.319149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.691063</td>\n",
              "      <td>51.165448</td>\n",
              "      <td>0.689777</td>\n",
              "      <td>50.359043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.681885</td>\n",
              "      <td>54.901737</td>\n",
              "      <td>0.689855</td>\n",
              "      <td>50.279255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.682941</td>\n",
              "      <td>53.896252</td>\n",
              "      <td>0.626653</td>\n",
              "      <td>66.489362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.580164</td>\n",
              "      <td>71.852148</td>\n",
              "      <td>0.569259</td>\n",
              "      <td>71.781915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>96.0</td>\n",
              "      <td>0.326940</td>\n",
              "      <td>98.388940</td>\n",
              "      <td>0.539139</td>\n",
              "      <td>76.515957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>97.0</td>\n",
              "      <td>0.326850</td>\n",
              "      <td>98.400366</td>\n",
              "      <td>0.539293</td>\n",
              "      <td>76.502660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>98.0</td>\n",
              "      <td>0.326579</td>\n",
              "      <td>98.428931</td>\n",
              "      <td>0.545046</td>\n",
              "      <td>76.050532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>99.0</td>\n",
              "      <td>0.326690</td>\n",
              "      <td>98.417505</td>\n",
              "      <td>0.539252</td>\n",
              "      <td>76.609043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>100.0</td>\n",
              "      <td>0.326442</td>\n",
              "      <td>98.440356</td>\n",
              "      <td>0.537367</td>\n",
              "      <td>76.875000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Epoch  Train_Loss  Train_Acc  Val_Loss    Val_Acc\n",
              "0     1.0    0.690962  51.868144  0.689750  50.319149\n",
              "1     2.0    0.691063  51.165448  0.689777  50.359043\n",
              "2     3.0    0.681885  54.901737  0.689855  50.279255\n",
              "3     4.0    0.682941  53.896252  0.626653  66.489362\n",
              "4     5.0    0.580164  71.852148  0.569259  71.781915\n",
              "..    ...         ...        ...       ...        ...\n",
              "95   96.0    0.326940  98.388940  0.539139  76.515957\n",
              "96   97.0    0.326850  98.400366  0.539293  76.502660\n",
              "97   98.0    0.326579  98.428931  0.545046  76.050532\n",
              "98   99.0    0.326690  98.417505  0.539252  76.609043\n",
              "99  100.0    0.326442  98.440356  0.537367  76.875000\n",
              "\n",
              "[100 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP0eU4Ty3DzV",
        "colab_type": "code",
        "outputId": "9afe8da9-b058-45b4-dd2a-a83f378f6585",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(training_stats['Train_Loss'], label=\"Train\")\n",
        "plt.plot(training_stats['Val_Loss'], label=\"Validation\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjCvCBFh3DzY",
        "colab_type": "code",
        "outputId": "fa28440c-f57e-43b6-abd3-814714e742e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "plt.plot(training_stats['Train_Acc'], label=\"Train\")\n",
        "plt.plot(training_stats['Val_Acc'], label=\"Validation\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgmsie9M3Dzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
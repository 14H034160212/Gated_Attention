{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "D0T3nxESJstz",
    "outputId": "7341ce37-5134-467c-9d54-16650d84097e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip3 install torchtext==0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a9sHZi8rIXBC"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdb\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions\n",
    "import torch.optim as optim\n",
    "from torch import nn \n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import Vectors, GloVe\n",
    "\n",
    "# from models.LSTM import LSTMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6CtSKjSRaQdd"
   },
   "outputs": [],
   "source": [
    "# model.py\n",
    "\n",
    "class GANet(torch.nn.Module):\n",
    "    def __init__(self, batch_size, num_classes, mlp_out_size, vocab_size, embedding_length, weights, aux_hidden_size = 100, backbone_hidden_size = 100, tau = 1, biDirectional_aux = False, biDirectional_backbone = False):\n",
    "        super(GANet, self).__init__() \n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_size : Size of the batch which is same as the batch_size of the data returned by the TorchText BucketIterator\n",
    "        output_size : 6 = (For TREC dataset)\n",
    "        hidden_sie : Size of the hidden_state of the LSTM   (// Later BiLSTM)\n",
    "        vocab_size : Size of the vocabulary containing unique words\n",
    "        embedding_length : Embeddding dimension of GloVe word embeddings\n",
    "        weights : Pre-trained GloVe word_embeddings which we will use to create our word_embedding look-up table \n",
    "\n",
    "        --------\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_classes = num_classes\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_length = embedding_length\n",
    "        self.aux_hidden_size = aux_hidden_size\n",
    "        self.backbone_hidden_size = backbone_hidden_size \n",
    "        self.mlp_out_size = mlp_out_size\n",
    "        self.biDirectional_aux = biDirectional_aux\n",
    "        self.biDirectional_backbone = biDirectional_backbone\n",
    "        self.tau = tau\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_length)\n",
    "        self.word_embeddings.weights = nn.Parameter(weights, requires_grad=False)\n",
    "\n",
    "        self.auxiliary = AuxiliaryNet(self.batch_size, self.aux_hidden_size, self.embedding_length, self.biDirectional_aux, tau = self.tau)\n",
    "        self.backbone = BackboneNet(self.batch_size, self.backbone_hidden_size, self.embedding_length, self.biDirectional_backbone)\n",
    "\n",
    "        if(self.biDirectional_backbone):\n",
    "            self.mlp = MLP(self.backbone_hidden_size * 2, self.mlp_out_size)\n",
    "            self.FF = nn.Linear(self.backbone_hidden_size * 2,num_classes)\n",
    "        else:\n",
    "            self.mlp = MLP(self.backbone_hidden_size, self.mlp_out_size)\n",
    "            self.FF = nn.Linear(self.backbone_hidden_size,num_classes)\n",
    "\n",
    "\n",
    "    def masked_Softmax(self, logits, mask):\n",
    "        mask_bool = mask>0\n",
    "        logits[~mask_bool] = float('-inf')\n",
    "        return torch.softmax(logits, dim=1)\n",
    "\n",
    "    \n",
    "    def forward(self,input_sequence, is_train = True):\n",
    "        input_ = self.word_embeddings(input_sequence)\n",
    "        g_t, p_t = self.auxiliary(input_, is_train)\n",
    "        out_lstm = self.backbone(input_)\n",
    "\n",
    "        if is_train:\n",
    "            e_t = self.mlp(out_lstm)\n",
    "#             alpha = torch.softmax(e_t*g_t, dim = 1)\n",
    "#             pdb.set_trace()\n",
    "            alpha_numerator = torch.exp(e_t)*g_t\n",
    "            alpha_denomenator = torch.sum(alpha_numerator, dim=1).repeat(e_t.shape[1],1,1).transpose(0,1)\n",
    "            alpha = alpha_numerator/alpha_denomenator\n",
    "        else:\n",
    "            e_t = self.mlp(out_lstm)               # change if possible!\n",
    "            alpha = self.masked_Softmax(e_t, g_t)\n",
    "            \n",
    "        c_t = torch.bmm(alpha.transpose(1,2), out_lstm)\n",
    "        logits = self.FF(c_t)\n",
    "        final_output = torch.softmax(logits, dim = -1)\n",
    "        # final_output = final_output.max(2)[1]\n",
    "        final_output = final_output.squeeze(1)\n",
    "\n",
    "        return final_output, g_t, alpha, p_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pdl-jRmHb5KA"
   },
   "outputs": [],
   "source": [
    "class AuxiliaryNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Arguments\n",
    "    ---------\n",
    "    batch_size : Size of the batch which is same as the batch_size of the data returned by the TorchText BucketIterator\n",
    "    aux_hidden_size : Size of the hidden_state of the LSTM   (* Later BiLSTM, check dims for BiLSTM *)\n",
    "    embedding_length : Embeddding dimension of GloVe word embeddings\n",
    "    --------\n",
    "    \"\"\"\n",
    "    def __init__(self, batch_size, auxiliary_hidden_size, embedding_length, biDirectional = False, num_layers = 1, tau=1):\n",
    "        super(AuxiliaryNet, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_size = auxiliary_hidden_size\n",
    "        self.embedding_length = embedding_length\n",
    "        self.biDirectional = biDirectional\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.aux_lstm = nn.LSTM(self.embedding_length, self.hidden_size, bidirectional = self.biDirectional, num_layers = self.num_layers, batch_first = True)   # Dropout  \n",
    "        if(self.biDirectional):\n",
    "            self.aux_linear = nn.Linear(self.hidden_size * 2,1)\n",
    "        else:\n",
    "            self.aux_linear = nn.Linear(self.hidden_size,1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.tau = tau\n",
    "\n",
    "\n",
    "    def forward(self, input_sequence, is_train = True, batch_size=None):\n",
    "\n",
    "        # input : Dimensions (batch_size x seq_len x embedding_length)\n",
    "        out_lstm, (final_hidden_state, final_cell_state) = self.aux_lstm(input_sequence) # ouput dim: (batch_size x seq_len x hidden_size) \n",
    "        out_linear = self.aux_linear(out_lstm)                                           # p_t dim: (batch_size x seq_len x 1)\n",
    "        p_t = self.sigmoid(out_linear)\n",
    "\n",
    "        if is_train:\n",
    "            p_t = p_t.repeat(1,1,2)\n",
    "            p_t[:,:,0] = 1 - p_t[:,:,0] \n",
    "            g_hat = F.gumbel_softmax(p_t, self.tau, hard=False)   \n",
    "#             print(\"p_t: \", p_t)\n",
    "            g_t = g_hat[:,:,1]\n",
    "            g_t = g_t.reshape(g_t.shape[0], g_t.shape[1], 1)\n",
    "#             print(\"g_t Gumbel: \", g_t)\n",
    "        else:\n",
    "            # size : same as p_t [ batch_size x seq_len x 1]\n",
    "#             print(\"Underlying probability distribution: \", p_t)\n",
    "            m = torch.distributions.bernoulli.Bernoulli(p_t)   \n",
    "            g_t = m.sample()\n",
    "            \n",
    "            # We do not want all the values of g_t for a sample to be 0\n",
    "            # Make all g_t's 1 when all are zero\n",
    "            gt_sum = g_t.sum(1)\n",
    "            x = (gt_sum == 0).nonzero()\n",
    "            x = x[:,0]\n",
    "            for i in x:\n",
    "                g_t[i,:,:] = torch.ones(g_t[i,:,:].shape)\n",
    "#             print(\"All zero: \", len(x))\n",
    "        return g_t, p_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YT9xWP_MAVmq"
   },
   "outputs": [],
   "source": [
    "class BackboneNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_size : Size of the batch which is same as the batch_size of the data returned by the TorchText BucketIterator\n",
    "        backbone_hidden_size : Size of the hidden_state of the LSTM   (* Later BiLSTM, check dims for BiLSTM *)\n",
    "        embedding_length : Embeddding dimension of GloVe word embeddings\n",
    "        --------\n",
    "    \"\"\"\n",
    "    def __init__(self, batch_size, backbone_hidden_size, embedding_length, biDirectional = False, num_layers = 2):\n",
    "\n",
    "        super(BackboneNet, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_size = backbone_hidden_size\n",
    "        self.embedding_length = embedding_length\n",
    "        self.biDirectional\t= biDirectional\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.backbone_lstm = nn.LSTM(self.embedding_length, self.hidden_size, bidirectional = self.biDirectional, batch_first = True, num_layers = self.num_layers)   # Dropout  \n",
    "\n",
    "    def forward(self, input_sequence, batch_size=None):\n",
    "        out_lstm, (final_hidden_state, final_cell_state) = self.backbone_lstm(input_sequence)   # ouput dim: ( batch_size x seq_len x hidden_size )\n",
    "        return out_lstm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x_eU0HR-j8lW"
   },
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.ff_1 = nn.Linear(self.input_dim, self.output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ff_2 = nn.Linear(self.output_dim,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x):\n",
    "        out_1 = self.ff_1(x)\n",
    "        out_relu = self.relu(out_1)\n",
    "        out_2 = self.ff_2(out_relu)\n",
    "        out_sigmoid = self.sigmoid(out_2)\n",
    "\n",
    "        return out_sigmoid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Swz_WT2mS3zq"
   },
   "outputs": [],
   "source": [
    "def clip_gradient(model, clip_value):\n",
    "    params = list(filter(lambda p: p.grad is not None, model.parameters()))\n",
    "    for p in params:\n",
    "        p.grad.data.clamp_(-clip_value, clip_value)\n",
    "    \n",
    "def train_model(model, optim, train_iter, epoch, batch_size):\n",
    "    total_epoch_loss = 0\n",
    "    total_epoch_acc = 0\n",
    "    # model.cuda()\n",
    "#     optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "    steps = 0\n",
    "    model.train()\n",
    "    for idx, batch in enumerate(train_iter):\n",
    "        text = batch.text[0]\n",
    "        target = batch.label\n",
    "        target = torch.autograd.Variable(target).long()\n",
    "        if torch.cuda.is_available():\n",
    "            text = text.cuda()\n",
    "            target = target.cuda()\n",
    "        if (text.size()[0] is not batch_size):# One of the batch returned by BucketIterator has length different than 32.\n",
    "            continue\n",
    "        optim.zero_grad()\n",
    "        prediction, g_t, alpha, p_t = model(text, is_train = True)\n",
    "        # print(\"prediction = \", prediction.shape)\n",
    "        # print(\"target = \", target.shape)\n",
    "        # print(\"prediction = \", prediction)\n",
    "        # print(\"target = \", target)\n",
    "        \n",
    "        # Modifies loss function\n",
    "        loss = loss_fn(prediction, target, g_t)\n",
    "\n",
    "        # Defualt - Cross entropy loss funtion\n",
    "#         loss = loss_fn(prediction, target)\n",
    "        \n",
    "        # print(\"loss = \", loss)\n",
    "        \n",
    "        num_corrects = (torch.max(prediction, 1)[1].view(target.size()).data == target.data).float().sum()\n",
    "        acc = 100.0 * num_corrects/len(batch)\n",
    "        loss.backward()\n",
    "        clip_gradient(model, 1e-1)\n",
    "        optim.step()\n",
    "        steps += 1\n",
    "        \n",
    "        # if steps % 10 == 0:\n",
    "            # print (f'Epoch: {epoch+1}, Idx: {idx+1}, Training Loss: {loss.item():.4f}, Training Accuracy: {acc.item(): .2f}%')\n",
    "            # break\n",
    "        \n",
    "        total_epoch_loss += loss.item()\n",
    "        total_epoch_acc += acc.item()\n",
    "\n",
    "        \n",
    "    return total_epoch_loss/len(train_iter), total_epoch_acc/len(train_iter)\n",
    "\n",
    "def eval_model(model, val_iter):\n",
    "    total_epoch_loss = 0\n",
    "    total_epoch_acc = 0\n",
    "    total_attention =  0\n",
    "    total_samples = 0 \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(val_iter):\n",
    "            text = batch.text[0]\n",
    "            if (text.size()[0] is not 32):\n",
    "                continue\n",
    "            target = batch.label\n",
    "            target = torch.autograd.Variable(target).long()\n",
    "            if torch.cuda.is_available():\n",
    "                text = text.cuda()\n",
    "                target = target.cuda()\n",
    "            prediction, g_t, alpha, p_t = model(text, is_train = False)\n",
    "            # Sanity check\n",
    "            # print(\"Test Prediction: \", prediction)\n",
    "            # print(\"Gate values: \", g_t)\n",
    "\n",
    "            # For density calculation\n",
    "            total_attention += torch.sum(g_t)\n",
    "            # print(total_attention)\n",
    "            # print(g_t.shape)\n",
    "            total_samples += g_t.shape[0] * g_t.shape[1]\n",
    "            \n",
    "            # Modifies loss function\n",
    "            loss = loss_fn(prediction, target, g_t)\n",
    "\n",
    "            # Defualt - Cross entropy loss funtion\n",
    "#             loss =  loss_fn(prediction, target)\n",
    "            \n",
    "            if math.isnan(loss.item()):\n",
    "                print(prediction, target)\n",
    "            \n",
    "            num_corrects = (torch.max(prediction, 1)[1].view(target.size()).data == target.data).sum()\n",
    "            acc = 100.0 * num_corrects/len(batch)\n",
    "            total_epoch_loss += loss.item()\n",
    "            total_epoch_acc += acc.item()\n",
    "            \n",
    "    return total_epoch_loss/len(val_iter), total_epoch_acc/len(val_iter), total_attention/total_samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vAjlrmkGSEQQ"
   },
   "outputs": [],
   "source": [
    "# data.py\n",
    "def load_IMDB_data(batch_size= 32, embedding_length = 100):\n",
    "    # set up fields\n",
    "    tokenize = lambda x: x.split()\n",
    "    TEXT = data.Field(sequential=True, tokenize=tokenize, lower=True, include_lengths=True, batch_first=True, fix_length=100)\n",
    "    # LABEL = data.LabelField()\n",
    "    LABEL = data.LabelField(dtype=torch.float)\n",
    "\n",
    "    # make splits for data\n",
    "    train, test = datasets.IMDB.splits(TEXT, LABEL)\n",
    "    train, valid = train.split() \n",
    "    \n",
    "    # build the vocabulary\n",
    "    TEXT.build_vocab(train, vectors=GloVe(name='6B', dim=embedding_length))\n",
    "    LABEL.build_vocab(train)\n",
    "    print(LABEL.vocab.__dict__)\n",
    "\n",
    "    # make iterator for splits\n",
    "    train_iter, valid_iter, test_iter = data.BucketIterator.splits(\n",
    "      (train, valid, test), batch_size= batch_size, device=0)\n",
    "\n",
    "    word_embeddings = TEXT.vocab.vectors\n",
    "    vocab_size = len(TEXT.vocab)\n",
    "\n",
    "    return TEXT, vocab_size, word_embeddings, train_iter, valid_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "xHuvlEncW_tw",
    "outputId": "ea08c54e-f4c1-4785-cf86-c072a8dd620f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'freqs': Counter({'pos': 8772, 'neg': 8728}), 'itos': ['pos', 'neg'], 'unk_index': None, 'stoi': defaultdict(None, {'pos': 0, 'neg': 1}), 'vectors': None}\n"
     ]
    }
   ],
   "source": [
    "# main.py\n",
    "TEXT, vocab_size, word_embeddings, train_iter, valid_iter, test_iter = load_IMDB_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dkoJVXJ2mzCD"
   },
   "outputs": [],
   "source": [
    "def loss_fn(output, target, g_t, lambda_ = 1e-4):\n",
    "#     T = g_t.shape[0]*g_t.shape[1]\n",
    "    T = len(g_t)\n",
    "    # loss = -nn.LogSoftmax(output[target], dim = 1) + (lambda_ * torch.sum(g_t))/T\n",
    "    loss = F.cross_entropy(output, target) + (lambda_ * torch.sum(g_t))/T\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PImJSOJmzQgT"
   },
   "outputs": [],
   "source": [
    "# Over-writing the loss function to simple cross entropy loss\n",
    "# loss_fn = F.cross_entropy\n",
    "\n",
    "learning_rate = 2e-5\n",
    "batch_size = 32\n",
    "output_size = 2\n",
    "hidden_size = 256\n",
    "embedding_length = 100\n",
    "num_classes = 2\n",
    "mlp_out_size = 32\n",
    "weights = word_embeddings\n",
    "aux_hidden_size = 100\n",
    "batch_hidden_size = 100\n",
    "tau = 1\n",
    "\n",
    "model = GANet(batch_size, num_classes, mlp_out_size, vocab_size, embedding_length, weights, tau= tau, biDirectional_aux=False, biDirectional_backbone=False)\n",
    "optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 830
    },
    "colab_type": "code",
    "id": "EcU6SSW8bDln",
    "outputId": "49069342-b9dd-4d4c-d2f3-6509dd836057"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "*** Least validation loss\n",
      "Train Loss: 0.606, Train Acc: 67.53%\n",
      "Val Loss: 0.589274, Val Acc: 70.44%, Val Density: 0.3734\n",
      "-------------\n",
      "Epoch: 02\n",
      "*** Least validation loss\n",
      "Train Loss: 0.490, Train Acc: 81.60%\n",
      "Val Loss: 0.569497, Val Acc: 72.41%, Val Density: 0.2714\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "num_bad_epochs = 0\n",
    "epoch = 0\n",
    "least_loss = float('inf')\n",
    "training_stats = pd.DataFrame(columns=['Epoch', 'Train_Loss', 'Train_Acc', 'Val_Loss', 'Val_Acc', 'Val_Density'])\n",
    "\n",
    "while(True):\n",
    "    train_loss, train_acc = train_model(model, optim, train_iter, epoch, batch_size)\n",
    "    val_loss, val_acc, val_density = eval_model(model, valid_iter) \n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    if val_loss < least_loss:\n",
    "        least_loss = val_loss\n",
    "        num_bad_epochs = 0\n",
    "        print(\"*** Least validation loss\")\n",
    "        torch.save(model.state_dict(), \"IMDB_LSTM+LSTM_100\")\n",
    "    else:\n",
    "        num_bad_epochs += 1\n",
    "#     print(f'Epoch: {epoch+1:2}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%')\n",
    "    print(f'Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%') \n",
    "    print(f'Val Loss: {val_loss:3f}, Val Acc: {val_acc:.2f}%, Val Density: {val_density:.4f}')\n",
    "    print(\"-------------\")\n",
    "    \n",
    "    training_stats = training_stats.append(\n",
    "        pd.Series([epoch+1, train_loss, train_acc, val_loss, val_acc, val_density], index=training_stats.columns), \n",
    "        ignore_index=True)\n",
    "#     if num_bad_epochs >= 10:\n",
    "#         break\n",
    "        \n",
    "    epoch += 1\n",
    "    if epoch == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_stats.to_csv(\"IMDB_LSTM+LSTM_100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print model's state_dict\n",
    "# print(\"Model's state_dict:\")\n",
    "# for param_tensor in model.state_dict():\n",
    "#     print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# # Print optimizer's state_dict\n",
    "# print(\"Optimizer's state_dict:\")\n",
    "# for var_name in optim.state_dict():\n",
    "#     print(var_name, \"\\t\", optim.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GANet(\n",
       "  (word_embeddings): Embedding(201739, 100)\n",
       "  (auxiliary): AuxiliaryNet(\n",
       "    (aux_lstm): LSTM(100, 100, batch_first=True, bidirectional=True)\n",
       "    (aux_linear): Linear(in_features=200, out_features=1, bias=True)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (backbone): BackboneNet(\n",
       "    (backbone_lstm): LSTM(100, 100, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (ff_1): Linear(in_features=200, out_features=32, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (ff_2): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (FF): Linear(in_features=200, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = GANet(batch_size, num_classes, mlp_out_size, vocab_size, embedding_length, weights, tau= tau, biDirectional_aux=False, biDirectional_backbone=False)\n",
    "loaded_model.load_state_dict(torch.load('IMDB_LSTM+LSTM_100'))\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "vwMLkn7s7cnC",
    "outputId": "86182669-19b9-4b8d-b9a4-815acf8d240e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.581, Test Acc: 71.75, Density: 0.2617 \n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, density = eval_model(loaded_model, test_iter)\n",
    "print(f'Test Loss: {test_loss:.3f}, Test Acc: {test_acc:.2f}, Density: {density:.4f} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kj2OOxjKaAIm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "['this', 'is', 'one', 'of', 'the', 'best', 'creation', 'of', 'nolan.', 'i', 'can', 'say,', \"it's\", 'his', 'magnum', 'opus.', 'loved', 'the', 'soundtrack', 'and', 'especially', 'those', 'creative', 'dialogues.']\n",
      "prediction = tensor([[1.0000e+00, 5.9342e-10]], grad_fn=<SqueezeBackward1>)\n",
      "this 0 0.9378951191902161 0.0\n",
      "is 1 0.9947400689125061 0.04351923242211342\n",
      "one 1 0.9948108196258545 0.04351923242211342\n",
      "of 1 0.9973734617233276 0.04351923242211342\n",
      "the 1 0.9971464276313782 0.04351923242211342\n",
      "best 1 0.9984948635101318 0.04351923242211342\n",
      "creation 1 0.9990401864051819 0.04351923242211342\n",
      "of 1 0.9986294507980347 0.04351923242211342\n",
      "nolan. 1 0.9942398071289062 0.04351923242211342\n",
      "i 1 0.9977445602416992 0.04351923242211342\n",
      "can 1 0.9989503026008606 0.04351923242211342\n",
      "say, 1 0.9984232187271118 0.04351923242211342\n",
      "it's 1 0.997162401676178 0.04351923242211342\n",
      "his 1 0.9973955154418945 0.04351923242211342\n",
      "magnum 1 0.9982940554618835 0.04351923242211342\n",
      "opus. 1 0.998584508895874 0.04351923242211342\n",
      "loved 1 0.9974555373191833 0.04351923242211342\n",
      "the 1 0.9969879984855652 0.04351923242211342\n",
      "soundtrack 1 0.996566653251648 0.04351923242211342\n",
      "and 1 0.9934771656990051 0.04351923242211342\n",
      "especially 1 0.995158851146698 0.04351923242211342\n",
      "those 1 0.9906125068664551 0.04351923242211342\n",
      "creative 1 0.9856093525886536 0.043384719640016556\n",
      "dialogues. 1 0.9890308976173401 0.04271142557263374\n",
      "tensor(0)\n",
      "------------\n",
      "['ohh,', 'such', 'a', 'ridiculous', 'movie.', 'not', 'gonna', 'recommend', 'it', 'to', 'anyone.', 'complete', 'waste', 'of', 'time', 'and', 'money.']\n",
      "prediction = tensor([[4.9471e-07, 1.0000e+00]], grad_fn=<SqueezeBackward1>)\n",
      "ohh, 1 0.7329792976379395 0.06050881743431091\n",
      "such 1 0.7010247111320496 0.06136245280504227\n",
      "a 1 0.7968748211860657 0.06163923442363739\n",
      "ridiculous 1 0.8645821809768677 0.06376536935567856\n",
      "movie. 1 0.9239889979362488 0.06342554092407227\n",
      "not 1 0.9565187096595764 0.062037188559770584\n",
      "gonna 1 0.9957849383354187 0.0623415932059288\n",
      "recommend 1 0.996605396270752 0.058946654200553894\n",
      "it 1 0.9972196817398071 0.06122850254178047\n",
      "to 1 0.9993890523910522 0.060084015130996704\n",
      "anyone. 1 0.998045802116394 0.06245581805706024\n",
      "complete 1 0.999049961566925 0.06173838675022125\n",
      "waste 1 0.9992607235908508 0.06236756965517998\n",
      "of 1 0.9972010850906372 0.05227808281779289\n",
      "time 1 0.9901174902915955 0.046496521681547165\n",
      "and 1 0.9899339079856873 0.04774033650755882\n",
      "money. 1 0.9896944761276245 0.0515839159488678\n",
      "tensor(1)\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "def test_sentence(test_sen):\n",
    "    test_sen_list = TEXT.preprocess(test_sen)\n",
    "    print(test_sen_list)\n",
    "    test_sen = [[TEXT.vocab.stoi[x] for x in test_sen_list]]\n",
    "    # print(test_sen)\n",
    "\n",
    "    test_sen = np.asarray(test_sen)\n",
    "    test_sen = torch.LongTensor(test_sen)\n",
    "    test_tensor = Variable(test_sen, volatile=True)\n",
    "\n",
    "    # print(test_tensor)\n",
    "    loaded_model.eval()\n",
    "    prediction, g_t, alpha, p_t = loaded_model(test_tensor, is_train = False)\n",
    "    print(\"prediction =\", prediction)\n",
    "#     print(\"g =\", g_t)\n",
    "    \n",
    "    for i in range(len(test_sen_list)):\n",
    "        print(test_sen_list[i], int(g_t[0][i]), float(p_t[0][i][0]), float(alpha[0][i][0]))\n",
    "    out_class = torch.argmax(prediction)\n",
    "    return out_class\n",
    "\n",
    "''' Let us now predict the sentiment on a single sentence just for the testing purpose. '''\n",
    "test_sen1 = \"This is one of the best creation of Nolan. I can say, it's his magnum opus. Loved the soundtrack and especially those creative dialogues.\"\n",
    "test_sen2 = \"Ohh, such a ridiculous movie. Not gonna recommend it to anyone. Complete waste of time and money.\"\n",
    "\n",
    "print('------------')\n",
    "x = test_sentence(test_sen1)\n",
    "print(x)\n",
    "print('------------')\n",
    "x = test_sentence(test_sen2)\n",
    "print(x)\n",
    "print('------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJf5OMBaO8Wl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train_Loss</th>\n",
       "      <th>Train_Acc</th>\n",
       "      <th>Val_Loss</th>\n",
       "      <th>Val_Acc</th>\n",
       "      <th>Val_Density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.606439</td>\n",
       "      <td>67.533135</td>\n",
       "      <td>0.589274</td>\n",
       "      <td>70.438830</td>\n",
       "      <td>tensor(0.3734)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.490295</td>\n",
       "      <td>81.604205</td>\n",
       "      <td>0.569497</td>\n",
       "      <td>72.406915</td>\n",
       "      <td>tensor(0.2714)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Epoch  Train_Loss  Train_Acc  Val_Loss    Val_Acc     Val_Density\n",
       "0     1    0.606439  67.533135  0.589274  70.438830  tensor(0.3734)\n",
       "1     2    0.490295  81.604205  0.569497  72.406915  tensor(0.2714)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(training_stats['Train_Loss'], label=\"Train\")\n",
    "plt.plot(training_stats['Val_Loss'], label=\"Validation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deVzVVf7H8dcRQVZRNncEV3YVca1c0kqtNJcaLSsts7HfTDPNTIplZbs1TVnTVGNNljOllbiVmW2WtqipKSCKooIiCoiyyCLb+f3BVZFYLnBX7uf5ePjw3u+933s/B7hvvpz7PZ+rtNYIIYSwP62sXYAQQoimkQAXQgg7JQEuhBB2SgJcCCHslAS4EELYqdaWfDI/Pz8dFBRkyacUQgi7t3v37jNaa/+a2y0a4EFBQezatcuSTymEEHZPKZVW23ajplCUUg8ppfYrpRKVUiuVUq5KqQ+UUsmGbe8qpZxNW7IQQoj6NBjgSqkuwINAjNY6AnACpgMfACFAJOAGzDFjnUIIIWowdgqlNeCmlCoD3IEMrfWXF29USu0EupqhPiGEEHVoMMC11ieVUi8Bx4Fi4Msa4e0M3An8qbb9lVJzgbkAgYGBv7m9rKyM9PR0SkpKmjQA8Vuurq507doVZ2eZ1RKiJWswwJVS7YFJQDCQC3yilJqptf6f4S5vAFu11ttq219rvQxYBhATE/Obxivp6el4eXkRFBSEUqqJwxAXaa3JyckhPT2d4OBga5cjhDAjY97EHAsc01pna63LgDXAcACl1BOAP/CXphZQUlKCr6+vhLeJKKXw9fWVv2iEcADGzIEfB4YqpdypmkIZA+xSSs0BbgDGaK0rm1OEhLdpyddTCMfQ4BG41noHsBrYAyQY9lkGvAV0AH5WSu1VSj1uzkKFEMIenSss5clP95NfUmbyxzbqLBSt9RPAE03Z19bl5OQwZswYAE6fPo2TkxP+/lULnnbu3ImLi0uDjzF79mxiY2Pp27evWWsVQtgPrTWfJ5zmiQ2J5BaVcVVPP8aGdTDpc7SIEG4OX19f9u7dC8DixYvx9PTkb3/72xX30VqjtaZVq9r/YFm+fLnZ6xRC2I+s/BIWrUvky6RMIrt48997hxDaqa3Jn0eaWdUhJSWFsLAw7rjjDsLDwzl16hRz584lJiaG8PBwnnrqqUv3vfrqq9m7dy/l5eW0a9eO2NhY+vXrx7Bhw8jKyrLiKIQQlqS15uNfTjDm5e/5/lA2C8eHsPaB4WYJb7CxI/AnP91PUka+SR8zrHNbnrg5vEn7Hjx4kBUrVhATEwPAkiVL8PHxoby8nNGjRzNt2jTCwsKu2CcvL4+RI0eyZMkS/vKXv/Duu+8SGxvb7HEIIWzb8ZwiFq6N58eUHAYH+/DC1CiC/TzM+pw2FeC2pmfPnpfCG2DlypX85z//oby8nIyMDJKSkn4T4G5ubowfPx6AgQMHsm1brafHCyFaiIpKzXs/pfLS5mScWimeuSWC2wcH0qqV+c8Gs6kAb+qRsrl4eFz+7Xn48GFeffVVdu7cSbt27Zg5c2at51pXf9PTycmJ8vJyi9QqhLC8w5kFzI+L59fjuYzu68+zkyPp3M7NYs9vUwFuy/Lz8/Hy8qJt27acOnWKzZs3M27cOGuXJYSwgtLySt76/givf5uCRxsnlv6uP5P6d7b4GgwJcCNFR0cTFhZGSEgI3bt356qrrrJ2SUIIK4hPz2X+6ngOni7g5n6deeLmMPw821ilFqX1b9qTmE1MTIyu+YEOBw4cIDQ01GI1OAr5ugphWsWlFSz9+hBvbzuKv1cbnrklkutMfF53XZRSu7XWMTW3yxG4EEI0YPvRHGLj4knNKWLG4G4snBBKW1frd/uUABdCiDoUlJSxZNNBPthxnEAfdz6cM4ThvfysXdYlEuBCCFGLbw9m8ujaRDLzS5hzdTB/vb4vbi5O1i7rChLgQghRzdnCUp76dD/r9mbQp4Mnb9wxnAGB7a1dVq0kwIUQgqpl8J/Gn2Lxhv0UlJTx57G9eWBUL1xa227HEQlwIYTDO51XwqJ1CXx9IIt+3drx4tQo+nb0snZZDbLdXy0WMnr0aDZv3nzFtqVLlzJv3rw69/H09AQgIyODadOm1XqfUaNGUfOUyZqWLl1KUVHRpesTJkwgNzfX2NKFEM2ktWblzuNc9/L3/JByhkU3hrJm3nC7CG+QAGfGjBmsWrXqim2rVq1ixowZDe7buXNnVq9e3eTnrhngn3/+Oe3atWvy4wkhjJeWU8jtb+9g4ZoEIrp4s/nPI5hzTQ+cLNDDxFQcPsCnTZvGxo0bKS0tBSA1NZWMjAwGDBjAmDFjiI6OJjIykvXr1/9m39TUVCIiIgAoLi5m+vTphIaGMnnyZIqLiy/db968eZfa0D7xRNXnYrz22mtkZGQwevRoRo8eDUBQUBBnzpwB4OWXXyYiIoKIiAiWLl166flCQ0O57777CA8P5/rrr7/ieYQQDauo1Lyz7Sg3LN1K4sk8np8SyYf3DaG7r3k7B5qDbc2Bb4qF0wmmfcyOkTB+SZ03+/j4MHjwYDZt2sSkSZNYtWoVt912G25ubqxdu5a2bdty5swZhg4dysSJE+vsdfDmm2/i7u7OgQMHiI+PJzo6+tJtzz77LD4+PlRUVDBmzBji4+N58MEHefnll9myZQt+fleeV7p7926WL1/Ojh070FozZMgQRo4cSfv27Tl8+DArV67k7bff5rbbbiMuLo6ZM2ea5mslRAuXfLqq+dS+E7mMDQ3gmVsi6ejtau2ymszhj8DhymmUi9MnWmseeeQRoqKiGDt2LCdPniQzM7POx9i6deulII2KiiIqKurSbR9//DHR0dEMGDCA/fv3k5SUVG89P/zwA5MnT8bDwwNPT0+mTJlyqS1tcHAw/fv3B6ra1aampjZn6EI4hNLySl756hA3/XMb6WeL+OeMAbx9V4xdhzcYeQSulHoImANoqj7YeDbQCVgF+AK7gTu11qXNqqaeI2VzmjRpEg899BB79uyhqKiIgQMH8t5775Gdnc3u3btxdnYmKCio1vaxDTl27BgvvfQSv/zyC+3bt2fWrFlNepyL2rS53DTHyclJplCEaMDeE7nMX72PQ5nnuaV/Zx6/ORwfj4Y/69YeNHgErpTqAjwIxGitIwAnYDrwAvCK1roXcA6415yFmpOnpyejR4/mnnvuufTmZV5eHgEBATg7O7NlyxbS0tLqfYwRI0bw4YcfApCYmEh8fDxQ1YbWw8MDb29vMjMz2bRp06V9vLy8KCgo+M1jXXPNNaxbt46ioiIKCwtZu3Yt11xzjamGK4RDKC6t4JnPkpjyxo8UlJTz7qwYlk4f0GLCG4yfA28NuCmlygB34BRwLXC74fb3gcXAm6Yu0FJmzJjB5MmTL02l3HHHHdx8881ERkYSExNDSEhIvfvPmzeP2bNnExoaSmhoKAMHDgSgX79+DBgwgJCQELp163ZFG9q5c+cybtw4OnfuzJYtWy5tj46OZtasWQwePBiAOXPmMGDAAJkuEcJIPx05Q2xcAsfPFnHHkEBix4fgZQPNp0zNqHaySqk/Ac8CxcCXwJ+A7Yajb5RS3YBNhiP0mvvOBeYCBAYGDqx5JCttT81Dvq7CEeWXlPH85wdYufMEQb7uLJkaxdAevtYuq9ma3E5WKdUemAQEA7nAJ4DRH0WjtV4GLIOqfuDG7ieEEI3xVVImi9YlkF1wgftH9ODPY/vYXPMpUzNmCmUscExrnQ2glFoDXAW0U0q11lqXA12Bk+YrUwghanfm/AUWb9jPZ/GnCOnoxdt3xRDV1TEWxBkT4MeBoUopd6qmUMYAu4AtwDSqzkS5G/jtShcjaa0t/llyLZklP2VJCGvRWrN+bwZPfrqfwgsV/PW6Ptw/sqdNN58ytQYDXGu9Qym1GtgDlAO/UjUlshFYpZR6xrDtP00pwNXVlZycHHx9fSXETUBrTU5ODq6u9n1+qxD1ycgtZtG6RL49mMWAwKrmU7072Ef/ElOy+mdilpWVkZ6e3qxzo8WVXF1d6dq1K87OLe9dd+HYKis1H+48zpJNB6mo1Dx8Q1/uHh5kV/1LmsJmPxPT2dmZ4OBga5chhLBxx84UEhsXz45jZ7m6lx/PT4mkm4+7tcuyKqsHuBBC1Ke8opL//HCMl786hEvrVrw4NYpbY7rKlCsS4EIIG5aUkc+CuHgSTuZxfVgHnr4lgg5t5f2diyTAhRA250J5Ba9/m8Kb3x2hnbsz/7o9mgmRHeWouwYJcCGETdmddo4FcfGkZJ1nSnQXHrsxjPYtqH+JKUmACyFsQlFpOX/fnMx7P6XSqa0ry2cPYnTfAGuXZdMkwIUQVvfD4TPErokn/Vwxdw3rzvxxIXi2kXhqiHyFhBBWk1dUxrOfJ/HxrnR6+Hnw8f3DGBzsY+2y7IYEuBDCKr5IPM1j6xM5W1jKvFE9+dOY3rg6t+zmU6YmAS6EsKjsgqrmUxsTThHWqS3LZw0ioou3tcuySxLgQgiL0FqzZs9JnvosieLSCh6+oS9zR/TA2clxmk+ZmgS4EMLsTuYW88iaBL4/lM3A7u15YWoUvQI8rV2W3ZMAF0KYTWWl5n870nhh00E08OTEcO4c2p1WLbz5lKVIgAshzOJI9nli4+L5JfUc1/T247nJ0nzK1CTAhRAmVVZRydvbjrL068O4OTvx0q39mBrdRZbBm4EEuBDCZBJP5rEgLp79GfmMj+jIk5PCCfCS5lPmIgEuhGi2krIK/vntYd76/ijt3V14845oxkd2snZZLZ4EuBCiWXalnmV+XDxHswuZNrAri24MpZ27NJ+yBAlwIUSTnL9Qzt+/OMiK7Wl09nZjxT2DGdHH39plOZQGA1wp1Rf4qNqmHsDjwHfAW4ArVR92/IDWeqcZahRC2JjvD2XzyJoEMvKKuXtYEA/f0BcPaT5lccZ8Kn0y0B9AKeUEnATWAm8DT2qtNymlJgAvAqPMV6oQwtpyi0p5+rMDxO1Jp6e/B5/cP4yYIGk+ZS2N/ZU5BjiitU5TSmmgrWG7N5Bh0sqEEDZlU8IpHlu/n3NFpfxhdC/+cG0vaT5lZY0N8OnASsPlPwOblVIvAa2A4bXtoJSaC8wFCAwMbGKZQghrycov4fH1+/li/2nCO7fl/XsGEd5Zmk/ZAqW1Nu6OSrlQdZQdrrXOVEq9BnyvtY5TSt0GzNVaj63vMWJiYvSuXbuaXbQQwvy01qzenc7TnyVRUl7JQ2P7cN81wbSW5lMWp5TarbWOqbm9MUfg44E9WutMw/W7gT8ZLn8CvNO8EoUQtuLE2SIeWZvAtsNnGBzkw5KpkfTwl+ZTtqYxAT6Dy9MnUHU0PpKqs1GuBQ6briwhhDVUVGpW/JzK3zcno4CnJ4VzxxBpPmWrjApwpZQHcB1wf7XN9wGvKqVaAyUY5rmFEPYpJauABXEJ7E47x8g+/jw3JZIu7dysXZaoh1EBrrUuBHxrbPsBGGiOooQQllNWUcm/vz/Ca9+k4N7GiZdv68fkAdJ8yh7ImfdCOLDEk3k8vDqeA6fyuTGqE4tvDsffq421yxJGkgAXwgGVlFWw9OvDvL3tKL4eLvz7zoHcEN7R2mWJRpIAF8LB7DiaQ+yaBI6dKeR3Md145MZQvN2crV2WaAIJcCEcREFJGS9+kcx/t6fRzceND+YM4apeftYuSzSDBLgQDmBLchaPrkngVH4J91wVzN9u6IO7i7z87Z18B4Vowc4VlvL0Z0ms+fUkvQM8iZs3nOjA9tYuS5iIBLgQLZDWmo0Jp3hi/X7yist48Npe/N+1vWjTWppPtSQS4EK0MJn5JSxal8hXSZlEdfXmf3OGENqpbcM7CrsjAS5EC6G15uNdJ3hm4wFKyyt5ZEII91wlzadaMglwIVqA4zlFxK6J56cjOQwJ9uGFqVEE+XlYuyxhZhLgQtixikrNez+l8tLmZJxaKZ6dHMGMQYHSfMpBSIALYacOZRYwf3U8e0/kcm1IAM9OjqCTtzSfciQS4ELYmdLySt787givbzmMZ5vWvDq9PxP7dZbmUw5IAlwIO7LvRC4L4uI5eLqAif0688TNYfh6SvMpRyUBLoQdKC6t4JWvD/HOtqMEeLnyzl0xjA3rYO2yhJVJgAth434+ksPCNfGk5hQxY3AgCyeE0NZVmk8JCXAhbFZ+SRlLNh3kwx3H6e7rzof3DWF4T2k+JS6TABfCBn1zIJNH1yaSVVDCfdcE85fr+uLmIsvgxZUkwIWwITnnL/Dkp0ls2JdB3w5evHXnQPp3a2ftsoSNajDAlVJ9gY+qbeoBPK61XqqU+iPwf0AFsFFrPd88ZQrRsmmt2bAvgyc/TaKgpIyHxvZh3qieuLSWZfCibg0GuNY6GegPoJRyAk4Ca5VSo4FJQD+t9QWlVIBZKxWihTqVV8yitYl8czCLft3a8eLUKPp29LJ2WcIONHYKZQxwRGudppT6O7BEa30BQGudZfLqhGjBKis1q345wfOfH6CsspJFN4Yy+6pgnGQZvDBSYwN8OrDScLkPcI1S6lmgBPib1vqXmjsopeYCcwECAwObUaoQLUfqmUJi18Sz/ehZhvXwZcnUSLr7SvMp0ThGB7hSygWYCCystq8PMBQYBHyslOqhtdbV99NaLwOWAcTExFxxmxCOpryikuU/pvKPr5JxbtWKJVMi+d2gbrIMXjRJY47AxwN7tNaZhuvpwBpDYO9USlUCfkC2iWsUokU4eDqfBavj2Zeex9jQDjxzSwQdvV2tXZawY40J8Blcnj4BWAeMBrYopfoALsAZE9YmRItwobyCf205whtbUvB2c+afMwZwU1QnOeoWzWZUgCulPIDrgPurbX4XeFcplQiUAnfXnD4RwtH9evwcC+LiOZR5nskDuvDYTWH4eLhYuyzRQhgV4FrrQsC3xrZSYKY5ihLC3hWVlvOPLw/x7o/H6NjWlXdnxXBtiDSfEqYlKzGFMLGfUs4QuyaB42eLmDk0kAXjQvCS5lPCDCTAhTCRvOIynv/8AKt+OUGQrzur5g5laA/fhncUookkwIUwgS/3n2bRukTOnL/A/SN78NDYPrg6S/MpYV4S4EI0w5nzF1i8YT+fxZ8ipKMX79wdQ1RXaT4lLEMCXIgm0Fqzbu9Jnvw0iaILFfz1uj78flRPnJ2k+ZSwHAlwIRopI7eYR9cmsCU5mwGBVc2neneQ5lPC8iTAhTBSZaXmg53HeWHTQSoqNY/fFMbdw4Ok+ZSwGglwIYxwNPs8sXEJ7Ew9y9W9/Hh+SiTdfNytXZZwcBLgQtSjvKKSd344xitfHaJN61a8OC2KWwd2lWXwwiZIgAtRh6SMfObH7SPxZD43hHfg6UkRBLSV5lPCdkiAC1HDhfIKXv82hTe/O0I7d2feuCOa8REd5ahb2BwJcCGq2Z1W1XwqJes8U6K78NiNYbSX5lPCRkmACwEUXijnpS+Tee+nVDp7u/He7EGM6isf8ypsmwS4cHjbDmezcE0C6eeKuXtYdx4eF4JnG3lpCNsnP6XCYeUVlfHMxiQ+2Z1OD38PPvn9MAYF+Vi7LCGMJgEuHNIXiad5bH0iZwtLeWBUTx4c01uaTwm7IwEuHEpWQQmLN+zn84TThHVqy/JZg4jo4m3tsoRoEglw4RC01sTtOcnTnyVRXFbBwzf0Ze6IHtJ8Stg1CXDR4qWfK+KRtYlsPZTNwO7teWFqFL0CPK1dlhDN1mCAK6X6Ah9V29QDeFxrvdRw+1+BlwB/rbV8Kr2wGZWVmv9uT+OFLw4C8OTEcO4c2p1W0nxKtBANBrjWOhnoD6CUcgJOAmsN17sB1wPHzVijEI12JPs8C1bHsyvtHCP6+PPc5Ai6tpfmU6JlaewUyhjgiNY6zXD9FWA+sN6kVQnRRGUVlSzbepRXvzmMm7MTL93aj6nRXWQZvGiRGhvg04GVAEqpScBJrfW++l4cSqm5wFyAwMDAJpYpRMMST+axIC6e/Rn5TIjsyOKJ4QR4SfMp0XIZHeBKKRdgIrBQKeUOPELV9Em9tNbLgGUAMTExuol1ClGnkrIKXvvmMP/eepT27i68NTOacRGdrF2WEGbXmCPw8cAerXWmUioSCAYuHn13BfYopQZrrU+boU4havVL6lkWrI7n6JlCbh3YlUU3huHt7mztsoSwiMYE+AwM0yda6wTgUqcfpVQqECNnoQhLOX+hnBe/OMiKn9Po2t6NFfcMZkQff2uXJYRFGRXgSikP4DrgfvOWI0TDvj+UzSNrEsjIK2bW8CAevqEvHtJ8Sjggo37qtdaFgG89tweZqiAh6pJbVMpTnyWxZs9Jevp7sPr3wxjYXZpPCcclhy3C5mmt2ZR4msfXJ5JbVMYfRvfiD9f2kuZTwuFJgAublpVfwmPrE9m8P5OILm15/57BhHeW5lNCgAS4sFFaaz7Znc4znyVxobyS2PEhzLk6mNbSfEqISyTAhc05cbaIhWsS+CHlDIODfFgyNZIe/tJ8SoiaJMCFzaio1Kz4OZUXv0imlYKnb4ngjsGB0nxKiDpIgAubkJJVwPzV8ew5nsuovv48OzmSLu3crF2WEDZNAlxYVVlFJW99d4R/fpuCexsnXvldP27pL82nhDCGBLiwmoT0PB5evY+Dpwu4MaoTT04Mx8+zjbXLEsJuSIALiyspq+CVrw/x9taj+Hm24d93DuSG8I7WLksIuyMBLixqx9EcYtckcOxMIdMHdWPhhFC83aT5lBBNIQEuLKKgpIwXvjjI/7Yfp5uPGx/MGcJVvfysXZYQdk0CXJjdloNZPLI2gdP5Jdx7dTB/vb4P7i7yoydEc8mrSJjN2cJSnvp0P+v2ZtA7wJO4ecOJDmxv7bKEaDEkwIXJaa35LP4UizfsJ6+4jAfH9Ob/RvekTWtpPiWEKUmAC5PKzC/h0bWJfH0gk6iu3vxvzhBCO7W1dllCtEgS4MIktNZ89MsJnv38AKXllTw6IZTZVwVJ8ynhuMqK4XwWFGZX/d9tMHiY9o17CXDRbMdziohdE89PR3IYEuzDC1OjCPLzsHZZQpjeFaGceWVAn8+8fLkwGy7kX7nv7Z9AnwY/B75RJMBFk1VUapb/eIyXvkymdatWPDc5kumDuknzKWFfjA3l81lQWlD7Y7h6g2cH8AiATlFV/3sa/nkEgKc/+PUxeekS4KJJkk8XMD8unn0ncrk2JIBnJ0fQyVuaTwkbcTGUz2dBYVY9AV1fKLe7HMCdogwB7V8tlC8GtD+0tk4LiAYDXCnVF/io2qYewONAF+BmoBQ4AszWWueao0hhO0rLK3njuxT+tSUFL1dnXp3en4n9OkvzKWF+pUWGMM6+HMq1BnS2kaHc73IAewbUCGjrhXJjNBjgWutkoD+AUsoJOAmsBfoCC7XW5UqpF4CFwAIz1iqsbN+JXOavjic5s4BJ/Tvz+E1h+ErzKdEcvwnlzDoC2ohQ9uwAnfpXC+UOVwa0nYRyYzR2CmUMcERrnQakVdu+HZhmsqqETSkureDlr5L5zw/HCPBy5Z27Yhgb1sHaZQlbVT2Uz2fWE9ANhbIhgC+GcvWpi4sB7eEPrV0sOz4b0tgAnw6srGX7PVw5zXKJUmouMBcgMDCwkU8nrO3nIznEroknLaeI24cEEjs+hLau0nzK4RgdyllQer72x3BrfzmAO/U3BLT/b9/wc/BQbgyltTbujkq5ABlAuNY6s9r2R4EYYIpu4MFiYmL0rl27mlGusJT8kjKe//wgK3cep7uvO89PiWR4T2k+1aJcCuUaUxW/CWgjQ7n6GRceAVcGtIRysyildmutY2pub8wR+HhgT43wngXcBIxpKLyF/fg6KZNH1yWQXXCBuSN68NDYPri5yDJ4u1BaVON85LoCOtu4UO484HIoXzxNTkLZZjQmwGdQbfpEKTUOmA+M1FoXmbowYXk55y/w5KdJbNiXQUhHL5bdGUO/bu2sXZYoLaxnwUj1gDYylLtE1x7Knh3A3U9C2Y4YFeBKKQ/gOuD+aptfB9oAXxlOIduutf69ySsUZqe1ZsO+DBZv2M/5C+U8NLYP80b1xKW1LIM3G1OF8sU38i6Fco2pDAnlFs2oANdaFwK+Nbb1MktFwqJO5RWzaG0i3xzMon+3drw4LYo+HbysXZZ9uiKUG1hmXWco+1w+y6JLdN2LRySUBbIS02FVVmpW/nKc5z8/SHllJYtuDGX2VcE4yTL4K10MZWNW9JUV1v4YV4TywPoXjzjJGT7CeBLgDujYmUJi4+LZcewsw3v6smRKFIG+7tYuy3JqC+W6VvQ1FMqeATVCuZbFIxLKwkwkwB1IeUUl7/54jH98eQgXp1YsmRLJ7wZ1axnL4EsL61nF15hQNpz61iWmnsUjfhLKwiZIgDuIA6fyWRAXT3x6HmNDO/DMLRF09Ha1dln1u3De+GXWdYWyu+/lN/S6xNSzeERCWdgfCfAW7kJ5Bf/acoQ3tqTg7ebM67cP4MbITtY76q4eyrUtGGlsKHcdVM/iEQll0bJJgLdge46fY8HqeA5nnWfygC48flMY7T3McOaC0aGcBWV1LBm4FMoBEspCGEkCvAUqKi3nH18e4t0fj9GxrSvLZw1idEhA4x7kUijXsYqvwVBW4O5TeyjXtnjESX4UhWgsedW0MD+mnCF2TTwnzhYzc2ggC8aF4HWx+dSF8/UvGKl+vnJ9oXzx1LdLoVzH4hEJZSHMSl5h9s4QyufPnmLN1l85dPQIc9yLGBfVig4lBfC/aucr1xnKvpfPsug2uP7FIxLKQtgMeTXaGq2rVunVt4rv/G9D2RO4C8AZdJlCpVcP5SE1Fo9UC2YJZSHslrxyLeE3oVzLKr7q5ys3dKTsGQDdhlDk4sPmtEq2ZbTCzacTs64bTO8ePVASykI4BHmVN1X1UK5rwUj1Oeby4loe5GIoG86yuHikXFtfZXffS6GstWbtryd56rMkii5U8ODYXtw/sifOTtJ8SghHIgFeXV2hXP0sjOoLSuoKZQ+/ywFcWyhfPAujWigb62RuMY+uTeC75GyiA6uaT/UKkOZTQjiilh/gxoRy9XOXjQnlwGG1v8nXxFA2RmWl5oMdaSzZdJBKDU/cHMZdw4Kk+ZQQDsw+A1xruFBgxKeOGBvKAVjErIAAAAtOSURBVODb0+KhbKyj2eeJjUtgZ+pZru7lx/NTIunm40DNp4QQtbKPAN+zApI3XRnQjQ3l6qfGXZxTbmXbHxNWXlHJ29uO8crXh3Bt3YoXp0Vx68CuLaP5lBCi2ewjwPMzIPd4VQBfCuUabTvtJJSNlZSRz/y4fSSezOeG8A48PSmCgLY23nxKCGFR9hHgo2Kr/jmAkrIKXv82hbe+P0I7dxfevCOa8ZGdrF2WEMIG2UeAO4jdaWeZvzqeI9mFTI3uymM3hdLOXT42SwhRuwYDXCnVF/io2qYewOPACsP2ICAVuE1rfc70JbZ8hRfK+fvmZN7/OZXO3m68f89gRvbxt3ZZQggb12CAa62Tgf4ASikn4CSwFogFvtFaL1FKxRquLzBjrS3S1kPZLFyTQEZeMXcN7c7D40LwbCN/GAkhGtbYpBgDHNFapymlJgGjDNvfB75DAtxoeUVlPL0xidW70+nh78HH9w9jUJCPtcsSQtiRxgb4dGCl4XIHrfUpw+XTQIfadlBKzQXmAgQGBjalxhbni8RTPLZ+P2cLS3lgVE8eHNMbV+eWcfaMEMJyjA5wpZQLMBFYWPM2rbVWSuna9tNaLwOWAcTExNR6H0eRVVDCE+v3synxNGGd2rJ81iAiunhbuywhhJ1qzBH4eGCP1jrTcD1TKdVJa31KKdUJyDJ9eS2D1prVu9N5ZuMBissqePiGvswd0UOaTwkhmqUxAT6Dy9MnABuAu4Elhv/Xm7CuFuPE2SIeWZvAtsNniOneniVTo+gV4GntsoQQLYBRAa6U8gCuA+6vtnkJ8LFS6l4gDbjN9OXZr8pKzYqfU3lxczIKeGpSODOHdKeVNJ8SQpiIUQGutS4EfGtsy6HqrBRRQ0rWeWLj4tmVdo4Rffx5bnIEXdtL8ykhhGnJCccmVFZRybKtR3n168O4uTjxj1v7MSW6izSfEkKYhQS4iSSezGP+6niSTuUzIbIjT06MwN+rjbXLEkK0YBLgzVRSVsGr3xxm2daj+Hi48NbMaMZFSPMpIYT5SYA3wy+pZ1mwOp6jZwq5dWBXFt0Yhre7s7XLEkI4CAnwJjh/oZwXvzjIip/T6Nrejf/eO5hrekvzKSGEZUmAN9J3yVk8ujaRjLxiZl8VxN+u74uHNJ8SQliBJI+RzhWW8vTGJNbsOUmvAE9W/344A7u3t3ZZQggHJgHeAK01nyec5okNieQWlfHHa3vxh2t70aa1NJ8SQliXBHg9svJLWLQukS+TMons4s2Ke4YQ1rmttcsSQghAArxWWms+2ZXO0xuTKC2vJHZ8CHOuDqa1NJ8SQtgQCfAaTpwtYuGaBH5IOcPgYB+WTImkh780nxJC2B4JcIOKSs37P6Xy983JOLVSPHNLBLcPDpTmU0IImyUBDhzOLGB+XDy/Hs9lVF9/npscSed2btYuSwgh6uXQAV5aXslb3x/h9W9T8GjjxNLf9WdS/87SfEoIYRccNsDj03OZvzqeg6cLuCmqE4snhuPnKc2nhBD2w+ECvKSsgle+OsTb247i79WGZXcO5PrwjtYuSwghGs2hAnz70Rxi4+JJzSlixuBuxI4PxdtNmk8JIeyTQwR4QUkZSzYd5IMdxwn0cefDOUMY3svP2mUJIUSztPgA//ZgJo+uTSQzv4Q5Vwfzl+v74O7S4octhHAAxn6ocTvgHSAC0MA9QDHwFuAKlAMPaK13mqnORjtbWMpTn+5n3d4Megd48sa84QwIlOZTQoiWw9hD0VeBL7TW05RSLoA78DHwpNZ6k1JqAvAiMMo8ZRpPa82n8adYvGE/+cVl/GlMbx4Y3VOaTwkhWpwGA1wp5Q2MAGYBaK1LgVKllAYudnbyBjLMVKPRTudVNZ/6+kAm/bp688J9QwjpKM2nhBAtkzFH4MFANrBcKdUP2A38CfgzsFkp9RLQChhe285KqbnAXIDAwEBT1PwbWmtW/XKC5zYeoKyykkcnhHLP1cE4yTJ4IUQLprTW9d9BqRhgO3CV1nqHUupVIJ+qo+7vtdZxSqnbgLla67H1PVZMTIzetWuXiUqvkpZTSGxcAj8fzWFoDx+WTIkiyM/DpM8hhBDWpJTarbWOqbndmCPwdCBda73DcH01EAtcTdWROMAnVL3JaTEVlZrlPx7jpS+TcW7ViucmRzJ9UDdpPiWEcBgNBrjW+rRS6oRSqq/WOhkYAyQBPYCRwHfAtcBhcxZaXfLpquZT+07kMiYkgGcmR9DJW5pPCSEci7FnofwR+MBwBspRYDawHnhVKdUaKMEwz21OpeWVvPFdCv/akoKXqzOvTu/PxH7SfEoI4ZiMCnCt9V6g5vzLD8BAk1dUh70nclmwOp7kzAIm9e/M4zeF4SvNp4QQDswuliT+85vDvPL1IQK8XPnP3TGMCe1g7ZKEEMLq7CLAA33dmT44kNjxIbR1leZTQggBdhLgk/p3YVL/LtYuQwghbIp8zLoQQtgpCXAhhLBTEuBCCGGnJMCFEMJOSYALIYSdkgAXQgg7JQEuhBB2SgJcCCHsVIP9wE36ZEplA2lN3N0POGPCcuyBjNkxyJgdQ3PG3F1r7V9zo0UDvDmUUrtqa2jeksmYHYOM2TGYY8wyhSKEEHZKAlwIIeyUPQX4MmsXYAUyZscgY3YMJh+z3cyBCyGEuJI9HYELIYSoRgJcCCHslM0FuFJqnFIqWSmVopSKreX2Nkqpjwy371BKBVm+StMyYsx/UUolKaXilVLfKKW6W6NOU2pozNXuN1UppZVSdn3KmTHjVUrdZvg+71dKfWjpGk3NiJ/rQKXUFqXUr4af7QnWqNOUlFLvKqWylFKJddyulFKvGb4m8Uqp6GY9odbaZv4BTsARoAfgAuwDwmrc5wHgLcPl6cBH1q7bAmMeDbgbLs9zhDEb7ucFbAW2AzHWrtvM3+PewK9Ae8P1AGvXbYExLwPmGS6HAanWrtsE4x4BRAOJddw+AdgEKGAosKM5z2drR+CDgRSt9VGtdSmwCphU4z6TgPcNl1cDY5RSyoI1mlqDY9Zab9FaFxmubge6WrhGUzPm+wzwNPACUGLJ4szAmPHeB/xLa30OQGudZeEaTc2YMWugreGyN5BhwfrMQmu9FThbz10mASt0le1AO6VUp6Y+n60FeBfgRLXr6YZttd5Ha10O5AG+FqnOPIwZc3X3UvUb3J41OGbDn5bdtNYbLVmYmRjzPe4D9FFK/aiU2q6UGmex6szDmDEvBmYqpdKBz4E/WqY0q2rs671edvGhxqKKUmomEAOMtHYt5qSUagW8DMyycimW1JqqaZRRVP2FtVUpFam1zrVqVeY1A3hPa/0PpdQw4L9KqQitdaW1C7MXtnYEfhLoVu16V8O2Wu+jlGpN1Z9eORapzjyMGTNKqbHAo8BErfUFC9VmLg2N2QuIAL5TSqVSNVe4wY7fyDTme5wObNBal2mtjwGHqAp0e2XMmO8FPgbQWv8MuFLV8KklM+r1bixbC/BfgN5KqWCllAtVb1JuqHGfDcDdhsvTgG+14d0BO9XgmJVSA4B/UxXe9j43Cg2MWWudp7X201oHaa2DqJr3n6i13mWdcpvNmJ/rdVQdfaOU8qNqSuWoJYs0MWPGfBwYA6CUCqUqwLMtWqXlbQDuMpyNMhTI01qfavKjWftd2zrepT1E1TvYjxq2PUXVCxiqvsmfACnATqCHtWu2wJi/BjKBvYZ/G6xds7nHXOO+32HHZ6EY+T1WVE0bJQEJwHRr12yBMYcBP1J1hspe4Hpr12yCMa8ETgFlVP1VdS/we+D31b7P/zJ8TRKa+3MtS+mFEMJO2doUihBCCCNJgAshhJ2SABdCCDslAS6EEHZKAlwIIeyUBLgQQtgpCXAhhLBT/w+yGRngW//mMgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_stats['Train_Acc'], label=\"Train\")\n",
    "plt.plot(training_stats['Val_Acc'], label=\"Validation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3196, 0.0464, 0.4322, 0.3626],\n",
       "         [0.5285, 0.8189, 0.8507, 0.6704],\n",
       "         [0.4549, 0.1717, 0.9506, 0.4272]],\n",
       "\n",
       "        [[0.2678, 0.9349, 0.7817, 0.1599],\n",
       "         [0.5822, 0.6097, 0.1133, 0.1424],\n",
       "         [0.1226, 0.4948, 0.1211, 0.9528]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(2,3,4)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.3766, 1.0475, 1.5407, 1.4370],\n",
       "         [1.6964, 2.2680, 2.3412, 1.9549],\n",
       "         [1.5760, 1.1874, 2.5873, 1.5330]],\n",
       "\n",
       "        [[1.3070, 2.5469, 2.1852, 1.1734],\n",
       "         [1.7900, 1.8398, 1.1199, 1.1530],\n",
       "         [1.1304, 1.6402, 1.1288, 2.5930]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.6490, 4.5028, 6.4692, 4.9250],\n",
       "        [4.2274, 6.0269, 4.4339, 4.9194]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.exp(t), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.6490, 4.5028, 6.4692, 4.9250],\n",
       "         [4.6490, 4.5028, 6.4692, 4.9250],\n",
       "         [4.6490, 4.5028, 6.4692, 4.9250]],\n",
       "\n",
       "        [[4.2274, 6.0269, 4.4339, 4.9194],\n",
       "         [4.2274, 6.0269, 4.4339, 4.9194],\n",
       "         [4.2274, 6.0269, 4.4339, 4.9194]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.exp(t), dim=1).repeat(3,1,1).transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2961, 0.2326, 0.2382, 0.2918],\n",
       "         [0.3649, 0.5037, 0.3619, 0.3969],\n",
       "         [0.3390, 0.2637, 0.3999, 0.3113]],\n",
       "\n",
       "        [[0.3092, 0.4226, 0.4928, 0.2385],\n",
       "         [0.4234, 0.3053, 0.2526, 0.2344],\n",
       "         [0.2674, 0.2721, 0.2546, 0.5271]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(t)/torch.sum(torch.exp(t), dim=1).repeat(3,1,1).transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_t = torch.tensor([[[1.],\n",
    "#          [0.],\n",
    "#          [1.],\n",
    "#          [0.],\n",
    "#          [1.],\n",
    "#          [0.],\n",
    "#          [1.],\n",
    "#          [0.],\n",
    "#          [0.],\n",
    "#          [0.]],\n",
    "\n",
    "#         [[0.],\n",
    "#          [1.],\n",
    "#          [1.],\n",
    "#          [1.],\n",
    "#          [0.],\n",
    "#          [1.],\n",
    "#          [1.],\n",
    "#          [0.],\n",
    "#          [1.],\n",
    "#          [1.]],\n",
    "\n",
    "#         [[0.],\n",
    "#          [0.],\n",
    "#          [0.],\n",
    "#          [0.],\n",
    "#          [0.],\n",
    "#          [0.],\n",
    "#          [0.],\n",
    "#          [0.],\n",
    "#          [0.],\n",
    "#          [0.]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_t_sum = g_t.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_t_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = (g_t_sum == 0).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = x[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in x:\n",
    "#     print(\"Old g\", g_t[i,:,:])\n",
    "#     new_g = torch.ones(g_t[i,:,:].shape)\n",
    "#     g_t[i,:,:] = new_g\n",
    "#     print(\"New g\", g_t[i,:,:])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GANet_Torch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
